{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4ba140-92f9-4d86-932c-3c7dacaeba33",
   "metadata": {},
   "source": [
    "## What are we going to cover\n",
    "* get  a vision dataset from torchvision.datasets\n",
    "* architecture of a CNN with PyTorch\n",
    "* An end to end multi-class image classification problem\n",
    "* steps in modelling with CNNs in pytorch\n",
    "    * Creating a CNN model with PyTorch\n",
    "    * Picking a Loss and optimizer\n",
    "    * Training a model a model\n",
    "    * Evaluating a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8ec8cb-3cf5-4b51-a0c7-297bc44078bb",
   "metadata": {},
   "source": [
    "## Computer Vision Libraries\n",
    "* `torchvision` -base domain library for  computer vision\n",
    "* `torchvision.datasets` - get datasets and data loading function for computer vision\n",
    "* `torchvision.models` - get pretrained computer vision models that you can leverage for your own problems\n",
    "* `torchvision.transforms` - functions for manipulating your vision data(images)  to be suitable for use with an ML model\n",
    "* `torch.utils.data.Dataset` - Base dataset class for PyTorch (creates custom data with your own datasets)\n",
    "* `torch.utils.data.DataLoader` - Creates a Python iterable over a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9feb3c9-4e12-4e78-b4d8-3cab9ff4b8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "0.20.1\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "#import torchvision\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor # `ToTensor` --> Convert a PIL image or numpy.ndarray to tensor\n",
    "\n",
    "\n",
    "#import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Check versions\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a43f1d9-0c15-425f-8ee3-6ef37e7a27c2",
   "metadata": {},
   "source": [
    "## Getting a Dataset\n",
    "The dataset we are going to use is -- **`FashionMNIST`** from torchvison.datasets-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4ccb582-9833-4cec-a3c3-6bcf9c1c5a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root = \"data\", #where to download data to\n",
    "    train = True, # do we want the training dataset? if train = False it will upload the test dataset\n",
    "    download = True, #do we want to download the data? (Yes/No)\n",
    "    transform = ToTensor(), #how do we want to transform the data\n",
    "    # `transform` convert the pil image or np.ndarray into pytorch, it converts the image (H*W*C) in the range [0,255] to \n",
    "    # a torch.FloatTensor of shape (C*W*H) in the range [0.0,1]\n",
    "    target_transform =None # how do we want to transform the labels/targets?\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor(),\n",
    "    target_transform = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e485cc-4550-4917-84d3-c0893ed743d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'T-shirt/top': 0,\n",
       " 'Trouser': 1,\n",
       " 'Pullover': 2,\n",
       " 'Dress': 3,\n",
       " 'Coat': 4,\n",
       " 'Sandal': 5,\n",
       " 'Shirt': 6,\n",
       " 'Sneaker': 7,\n",
       " 'Bag': 8,\n",
       " 'Ankle boot': 9}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#access some train data\n",
    "class_names_w_idx = train_data.class_to_idx\n",
    "class_names_w_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a0d9360-ff4b-4c23-8c54-9479988e2100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58afab69-1534-4f62-a01c-ee5e6bdb8d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2f6ee7-2e68-4dc8-a20a-ffd444daff83",
   "metadata": {},
   "source": [
    "## Visualizing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1361ac24-2c7d-402c-b432-6e69cac60da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1608c5e50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image, label = train_data[0]\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "plt.title(class_names[label])\n",
    "plt.imshow(image.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a24af6f-2be4-472e-bf8b-eb546a9d6081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#gray mapping images\n",
    "plt.imshow(image.squeeze(),cmap = 'gray')\n",
    "plt.title(class_names[label])\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2869fb1c-9d82-45d6-952a-381b37a2e1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#torch.manual_seed(42)\n",
    "\n",
    "fig = plt.figure(figsize = (9,9))\n",
    "rows ,cols = 4,4\n",
    "for i in range(1, rows*cols +1):\n",
    "    random_idx = torch.randint(0,len(train_data), size = [1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(),cmap = 'gray')\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False);\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "025c392e-2e12-4254-8a01-0744e6e59956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset FashionMNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: ToTensor(),\n",
       " Dataset FashionMNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: ToTensor())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2054f00c-1bf4-4f01-b4c2-410b8b8628ce",
   "metadata": {},
   "source": [
    "# `Prepare DataLoader` (Train and Test Data)\n",
    "\n",
    "Right now, our data is in the from of PyTorch Datasets\n",
    "\n",
    "DataLoader turns our dataset into a PyTorch iterable\n",
    "\n",
    "More specifically, we want to turn our data into batches(mini batches)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8439c153-c8a4-41da-b094-52b78f1f5620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x102977e90>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x16089fe90>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "#batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "#turn datasets into iterable(batches)\n",
    "train_dataloader = DataLoader(dataset = train_data,\n",
    "                        batch_size = BATCH_SIZE,\n",
    "                        shuffle = True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset = test_data,\n",
    "                        batch_size = BATCH_SIZE,\n",
    "                        shuffle = False)\n",
    "\n",
    "train_dataloader,test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e58c53b-98ff-4ab9-9a50-6cecc8a850ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1875"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c6a766a-30ab-4c74-ac0b-689fe36fd591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DataLoaders: (<torch.utils.data.dataloader.DataLoader object at 0x102977e90>, <torch.utils.data.dataloader.DataLoader object at 0x16089fe90>)\n",
      " Length of train dataloader : 1875 batches of 32\n",
      " Length of test dataloader : 313 batches of 32\n"
     ]
    }
   ],
   "source": [
    "#check out the status \n",
    "\n",
    "print(f\" DataLoaders: {train_dataloader,test_dataloader}\")\n",
    "print(f\" Length of train dataloader : {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\" Length of test dataloader : {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea1cb2e8-799b-446d-9a1f-a20859a22651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.sampler.BatchSampler at 0x153cb0f50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check out what's inside of the train_DataLoader\n",
    "train_dataloader.batch_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50979903-542f-4653-a82b-0bd11ff5508e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check out what's inside the train dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape #train_labels_batch represents the associted number of target values inside of a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22c08d48-6b27-48d6-bbd4-c56dd1f81ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_batch.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d9bee31-2531-43ab-85df-6c7b5b6db720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b95155d-2912-4530-b1d3-21c16f011323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_features_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3e88fb3-a769-4873-b720-d4464e7c2d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         ...,\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "print(train_features_batch.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9758fa7d-1451-4e0d-9759-0b3b1298eef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "939f1bfc-b8b4-4864-a5f7-b1f1bc514d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The representation of 30th image \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show a sample of a particular batch\n",
    "\n",
    "random_idx = torch.randint(0,len(train_features_batch),size =[1]).item()\n",
    "image, label = train_features_batch[random_idx],train_labels_batch[random_idx]\n",
    "\n",
    "#got the image and the associated label\n",
    "print(f\"The representation of {random_idx}th image \")\n",
    "plt.imshow(image.squeeze(),cmap = 'gray')\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0c4e4f-0614-447f-ba8f-d6d1668bf45f",
   "metadata": {},
   "source": [
    "# Baseline `Model` with two Linear Layers\n",
    "\n",
    "when starting to build a series of ML modelling experiments, it's best practice to start with a baseline model. \n",
    "\n",
    "A baseline model is a simple model you willl try and improve upon with subsequent models/experiments. \n",
    "\n",
    "In other words: Start simply and add complexity when necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16d94b18-0caf-4463-a1fd-c5c0734cba3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before flattening: torch.Size([1, 28, 28])\n",
      "Shape after flattening: torch.Size([1, 784])\n"
     ]
    }
   ],
   "source": [
    "# Create a flatten layer\n",
    "flatten_model = nn.Flatten()\n",
    "\n",
    "#get a single sample\n",
    "x = train_features_batch[0]\n",
    "\n",
    "#flatten the sample\n",
    "output = flatten_model(x) # performs the forward pass\n",
    "\n",
    "#print out what happened\n",
    "print(f\"Shape before flattening: {x.shape}\")\n",
    "print(f\"Shape after flattening: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf930466-fd49-4ff9-8a32-5f187a19f4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0118, 0.3686, 0.3843, 0.3843, 0.1922, 0.0000, 0.2000, 0.3216, 0.4314,\n",
       "          0.3686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.6471, 0.6863, 0.6157, 0.7176, 0.6863, 0.5216, 0.6824, 0.6431, 0.6667,\n",
       "          0.7255, 0.5529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4078,\n",
       "          0.6902, 0.6314, 0.6157, 0.5922, 0.5608, 0.6471, 0.5922, 0.6000, 0.6235,\n",
       "          0.6471, 0.7098, 0.3412, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0510,\n",
       "          0.6902, 0.6471, 0.6000, 0.6078, 0.6980, 0.7647, 0.5961, 0.5647, 0.6431,\n",
       "          0.6549, 0.6941, 0.1529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1176, 0.7216, 0.5922, 0.5843, 0.4667, 0.7098, 0.5843, 0.6431, 0.5922,\n",
       "          0.7255, 0.1294, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.6863, 0.5882, 0.6627, 0.6510, 0.4902, 0.5216, 0.5490, 0.5098,\n",
       "          0.6627, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.6196, 0.6549, 0.6235, 0.6863, 0.6196, 0.4196, 0.5176, 0.7922,\n",
       "          0.4706, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.3216, 0.7608, 0.6118, 0.6824, 0.6824, 0.6588, 0.5804, 0.7059,\n",
       "          0.3098, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039,\n",
       "          0.0000, 0.1294, 0.7059, 0.6000, 0.7216, 0.6353, 0.7216, 0.6275, 0.6510,\n",
       "          0.3961, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078,\n",
       "          0.0000, 0.2863, 0.7098, 0.5804, 0.6667, 0.6235, 0.6902, 0.5608, 0.7059,\n",
       "          0.4000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.3686, 0.7020, 0.6471, 0.6471, 0.7294, 0.7059, 0.6235, 0.6863,\n",
       "          0.4588, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039,\n",
       "          0.0000, 0.4824, 0.6588, 0.6078, 0.6863, 0.6353, 0.5412, 0.6353, 0.7059,\n",
       "          0.5922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.4471, 0.7333, 0.6902, 0.7098, 0.6902, 0.6235, 0.6275, 0.7216,\n",
       "          0.6902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.6667, 0.6471, 0.7529, 0.6745, 0.7020, 0.7882, 0.6667, 0.7020,\n",
       "          0.8039, 0.0471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0157, 0.7098, 0.6588, 0.7373, 0.7176, 0.7255, 0.7804, 0.5608, 0.5725,\n",
       "          0.6745, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1686, 0.7020, 0.6980, 0.7765, 0.7020, 0.7255, 0.7765, 0.7255, 0.5255,\n",
       "          0.7647, 0.4039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.2235, 0.8078, 0.6588, 0.7333, 0.6549, 0.7216, 0.8353, 0.7725, 0.6902,\n",
       "          0.7569, 0.5059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3490, 0.7882, 0.6431, 0.8980, 0.5961, 0.6706, 0.7608, 0.6667, 0.7176,\n",
       "          0.6902, 0.6235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3882, 0.7725, 0.6745, 0.8627, 0.6824, 0.8000, 0.7765, 0.6627, 0.6863,\n",
       "          0.7373, 0.6980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.4392, 0.7412, 0.6706, 0.8980, 0.6588, 0.6941, 0.8275, 0.6980, 0.6745,\n",
       "          0.7333, 0.6863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.4863, 0.7020, 0.7059, 0.9176, 0.6627, 0.7804, 0.8667, 0.4431, 0.5765,\n",
       "          0.7373, 0.8353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.5961, 0.7569, 0.6863, 0.7725, 0.6000, 0.8039, 0.7373, 0.6824, 0.6863,\n",
       "          0.7608, 0.8471, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.6118, 0.6902, 0.5216, 0.8314, 0.5373, 0.7804, 0.8275, 0.5804, 0.6510,\n",
       "          0.6510, 0.8275, 0.0314, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.6431, 0.5961, 0.7216, 0.8353, 0.6196, 0.7725, 0.8431, 0.3961, 0.5490,\n",
       "          0.6431, 0.8431, 0.0196, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.7333, 0.6471, 0.8039, 0.7765, 0.6667, 0.7216, 0.9294, 0.6078, 0.4784,\n",
       "          0.8392, 0.8745, 0.2588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549,\n",
       "          0.6471, 0.7686, 0.7098, 0.6157, 0.5725, 0.7098, 0.9412, 0.6588, 0.6314,\n",
       "          0.7176, 0.7569, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941,\n",
       "          0.8941, 0.7529, 0.8039, 0.9294, 0.6078, 0.7059, 1.0000, 0.7373, 0.7373,\n",
       "          0.7529, 0.9294, 0.5843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3098, 0.3490, 0.4000, 0.3608, 0.3804, 0.4824, 0.4941, 0.4118, 0.3137,\n",
       "          0.3725, 0.4157, 0.1686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000]]),\n",
       " tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0118, 0.3686, 0.3843, 0.3843, 0.1922, 0.0000, 0.2000, 0.3216, 0.4314,\n",
       "         0.3686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.6471, 0.6863, 0.6157, 0.7176, 0.6863, 0.5216, 0.6824, 0.6431,\n",
       "         0.6667, 0.7255, 0.5529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.4078, 0.6902, 0.6314, 0.6157, 0.5922, 0.5608, 0.6471, 0.5922,\n",
       "         0.6000, 0.6235, 0.6471, 0.7098, 0.3412, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0510, 0.6902, 0.6471, 0.6000, 0.6078, 0.6980, 0.7647,\n",
       "         0.5961, 0.5647, 0.6431, 0.6549, 0.6941, 0.1529, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.1176, 0.7216, 0.5922, 0.5843, 0.4667,\n",
       "         0.7098, 0.5843, 0.6431, 0.5922, 0.7255, 0.1294, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6863, 0.5882, 0.6627,\n",
       "         0.6510, 0.4902, 0.5216, 0.5490, 0.5098, 0.6627, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6196, 0.6549,\n",
       "         0.6235, 0.6863, 0.6196, 0.4196, 0.5176, 0.7922, 0.4706, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3216,\n",
       "         0.7608, 0.6118, 0.6824, 0.6824, 0.6588, 0.5804, 0.7059, 0.3098, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000,\n",
       "         0.1294, 0.7059, 0.6000, 0.7216, 0.6353, 0.7216, 0.6275, 0.6510, 0.3961,\n",
       "         0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0078,\n",
       "         0.0000, 0.2863, 0.7098, 0.5804, 0.6667, 0.6235, 0.6902, 0.5608, 0.7059,\n",
       "         0.4000, 0.0000, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.3686, 0.7020, 0.6471, 0.6471, 0.7294, 0.7059, 0.6235,\n",
       "         0.6863, 0.4588, 0.0000, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0039, 0.0000, 0.4824, 0.6588, 0.6078, 0.6863, 0.6353, 0.5412,\n",
       "         0.6353, 0.7059, 0.5922, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.4471, 0.7333, 0.6902, 0.7098, 0.6902,\n",
       "         0.6235, 0.6275, 0.7216, 0.6902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6667, 0.6471, 0.7529, 0.6745,\n",
       "         0.7020, 0.7882, 0.6667, 0.7020, 0.8039, 0.0471, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0157, 0.7098, 0.6588, 0.7373,\n",
       "         0.7176, 0.7255, 0.7804, 0.5608, 0.5725, 0.6745, 0.3059, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1686, 0.7020, 0.6980,\n",
       "         0.7765, 0.7020, 0.7255, 0.7765, 0.7255, 0.5255, 0.7647, 0.4039, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2235, 0.8078,\n",
       "         0.6588, 0.7333, 0.6549, 0.7216, 0.8353, 0.7725, 0.6902, 0.7569, 0.5059,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3490,\n",
       "         0.7882, 0.6431, 0.8980, 0.5961, 0.6706, 0.7608, 0.6667, 0.7176, 0.6902,\n",
       "         0.6235, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.3882, 0.7725, 0.6745, 0.8627, 0.6824, 0.8000, 0.7765, 0.6627, 0.6863,\n",
       "         0.7373, 0.6980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.4392, 0.7412, 0.6706, 0.8980, 0.6588, 0.6941, 0.8275, 0.6980,\n",
       "         0.6745, 0.7333, 0.6863, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.4863, 0.7020, 0.7059, 0.9176, 0.6627, 0.7804, 0.8667,\n",
       "         0.4431, 0.5765, 0.7373, 0.8353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.5961, 0.7569, 0.6863, 0.7725, 0.6000, 0.8039,\n",
       "         0.7373, 0.6824, 0.6863, 0.7608, 0.8471, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.6118, 0.6902, 0.5216, 0.8314, 0.5373,\n",
       "         0.7804, 0.8275, 0.5804, 0.6510, 0.6510, 0.8275, 0.0314, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6431, 0.5961, 0.7216, 0.8353,\n",
       "         0.6196, 0.7725, 0.8431, 0.3961, 0.5490, 0.6431, 0.8431, 0.0196, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7333, 0.6471, 0.8039,\n",
       "         0.7765, 0.6667, 0.7216, 0.9294, 0.6078, 0.4784, 0.8392, 0.8745, 0.2588,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0549, 0.6471, 0.7686,\n",
       "         0.7098, 0.6157, 0.5725, 0.7098, 0.9412, 0.6588, 0.6314, 0.7176, 0.7569,\n",
       "         0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0941, 0.8941,\n",
       "         0.7529, 0.8039, 0.9294, 0.6078, 0.7059, 1.0000, 0.7373, 0.7373, 0.7529,\n",
       "         0.9294, 0.5843, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.3098, 0.3490, 0.4000, 0.3608, 0.3804, 0.4824, 0.4941, 0.4118, 0.3137,\n",
       "         0.3725, 0.4157, 0.1686, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.squeeze(), output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "948e1a54-95e5-4eef-8238-476ef2f9d049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.1449, 0.6676, 0.3295],\n",
       "          [0.5059, 0.2155, 0.2067],\n",
       "          [0.7714, 0.4402, 0.7596]],\n",
       " \n",
       "         [[0.3147, 0.0695, 0.2158],\n",
       "          [0.1861, 0.5379, 0.1132],\n",
       "          [0.9979, 0.7484, 0.1359]]]),\n",
       " torch.Size([2, 3, 3]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((2,3,3)) #-->#height, length, width\n",
    "a,a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d9ecc224-28d0-4d92-9185-5507d1801cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1449, 0.6676, 0.3295, 0.5059, 0.2155, 0.2067, 0.7714, 0.4402, 0.7596],\n",
       "         [0.3147, 0.0695, 0.2158, 0.1861, 0.5379, 0.1132, 0.9979, 0.7484, 0.1359]]),\n",
       " torch.Size([2, 9]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_a = flatten_model(a) #--> #height, length*width\n",
    "flat_a,flat_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d96b8b73-ded3-4e54-bc00-359d5954ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self,\n",
    "                input_shape: int,\n",
    "                hidden_units: int, \n",
    "                output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape,\n",
    "                     out_features= hidden_units),\n",
    "            nn.Linear(in_features = hidden_units,\n",
    "                     out_features = output_shape)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9592cf35-2b23-4c0d-9d31-30949daa9b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mps'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device agnostic code\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31896e3c-929a-49e2-857b-1cf60e436b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FashionMNISTModelV0(\n",
       "  (layer_stack): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "model_0 = FashionMNISTModelV0(\n",
    "    input_shape=784, # this is 28*28\n",
    "    hidden_units = 10, \n",
    "    output_shape = len(class_names)\n",
    ")\n",
    "\n",
    "model_0.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cbad54-4638-4acd-b591-ca8a1f5adf19",
   "metadata": {},
   "source": [
    "# Loss Function and Optimizer\n",
    "* `Loss Function` - nn.CrossEntropyLoss()\n",
    "*  `optimizer` - torch.optim.SGD\n",
    "*  `Evaluation Matrix` - Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29d23781-b3cc-4750-ae55-e5e5475bdf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassAccuracy()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model_0.parameters(),\n",
    "                           lr = 0.01)\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "acc_fn = Accuracy(task = 'Multiclass',\n",
    "                  num_classes = 10\n",
    "                 ).to(device)\n",
    "acc_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de1e6e4e-20a7-4437-a54f-8766206e9a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helper_functions.py already exists, skipping download ....\n"
     ]
    }
   ],
   "source": [
    "#download the py file\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "#Download helper functions from Learn PyTorch repo\n",
    "if Path(\"helper_functions.py\").is_file():\n",
    "    print(\"helper_functions.py already exists, skipping download ....\")\n",
    "else:\n",
    "    print(\"Downloading helper_functions.py\")\n",
    "    request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "    with open(\"helper_functions.py\",\"wb\") as f:\n",
    "        f.write(request.content)\n",
    "        print(\"download Complete\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "530c5360-0bbc-4d9a-aeed-9e7d96b42a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37ab8019-1f22-48cc-8fe3-6f04df4ef624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function helper_functions.accuracy_fn(y_true, y_pred)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d4bf4c-d5ea-4429-b42b-56c259bdfcfa",
   "metadata": {},
   "source": [
    "## Creating a funtion to time our experiments\n",
    "\n",
    "Machine learning is very experimental\n",
    "\n",
    "2 of the main things you'll often want to track are:\n",
    "1. Model's performance\n",
    "2. How fast it runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06510d03-814c-4d43-88b5-e13ce0d529da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def print_train_time(start: float,\n",
    "                    end: float,\n",
    "                    device: torch.device = None):\n",
    "\n",
    "    \"\"\"Prints difference between start and end time. \"\"\"\n",
    "    total_time = end-start\n",
    "    print(f\"Train time on {device}: {total_time} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ce13c5b-8b6c-4f3d-9654-420883141410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time on mps: 0.00014004099648445845 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = timer()\n",
    "#some code\n",
    "end_time = timer()\n",
    "total_time = print_train_time(start_time,end_time,device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d0a9fbf-5ca5-499f-b90a-e78ee40a917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time on cpu: 2.5083994842134416e-05 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = timer()\n",
    "#some code\n",
    "end_time = timer()\n",
    "total_time = print_train_time(start_time,end_time,device = \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa9b13-f66e-440b-bace-6d8451680640",
   "metadata": {},
   "source": [
    "## Building Training and Testing Loop\n",
    "Highlight that the `optimizer` will update a model's `parameters` once `per batch` rather than once per epoch........"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df171df8-1ec0-4d30-bf1f-f13974350d05",
   "metadata": {},
   "source": [
    "1. Loop through epochs\n",
    "2. Loop through training batches, perform training steps, calculate the train loss per batch\n",
    "3. Loop through test batches, perform testing steps , calculate the test loss per batch\n",
    "4. Print out what's happening\n",
    "5. Time it all(for run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c796cabd-515c-4c7f-a2fb-f634a09ec591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4766eddab27437b832bdc0a7e13b050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "......\n",
      " Looked at 0/ 60000 samples.\n",
      " Looked at 12800/ 60000 samples.\n",
      " Looked at 25600/ 60000 samples.\n",
      " Looked at 38400/ 60000 samples.\n",
      " Looked at 51200/ 60000 samples.\n",
      " \n",
      "Train loss: 0.9096 | Test loss: 0.6290 | Test acc: 78.6342\n",
      "Epoch: 1\n",
      "......\n",
      " Looked at 0/ 60000 samples.\n",
      " Looked at 12800/ 60000 samples.\n",
      " Looked at 25600/ 60000 samples.\n",
      " Looked at 38400/ 60000 samples.\n",
      " Looked at 51200/ 60000 samples.\n",
      " \n",
      "Train loss: 0.5573 | Test loss: 0.5441 | Test acc: 81.1302\n",
      "Epoch: 2\n",
      "......\n",
      " Looked at 0/ 60000 samples.\n",
      " Looked at 12800/ 60000 samples.\n",
      " Looked at 25600/ 60000 samples.\n",
      " Looked at 38400/ 60000 samples.\n",
      " Looked at 51200/ 60000 samples.\n",
      " \n",
      "Train loss: 0.5027 | Test loss: 0.5137 | Test acc: 81.9988\n",
      "Train time on cpu: 6.949212708001141 seconds\n"
     ]
    }
   ],
   "source": [
    "model_0.to('cpu')\n",
    "from tqdm.auto import tqdm\n",
    "#set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "#set the number of epochs\n",
    "epochs = 3\n",
    "\n",
    "#create e training and test loop\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n......\")\n",
    "\n",
    "    #Training\n",
    "    train_loss = 0 #instantiate the training loss\n",
    "\n",
    "    #calculate the training loss per batch\n",
    "\n",
    "    # Per epoch calculate the loss of the total train datasets;\n",
    "\n",
    "    # Add a loop to loop through the training batches\n",
    "    for batch, (X,y) in enumerate(train_dataloader): # X --> image(features), y--> target label\n",
    "        model_0.train()\n",
    "\n",
    "        # 1. forward pass\n",
    "        y_pred = model_0(X) # X represents a full batch of image in our train dataloader\n",
    "\n",
    "        # 2. Loss calculation\n",
    "        loss = loss_fn(y_pred, y) #loss --> loss per batch\n",
    "        train_loss +=loss # Accumulate train loss # train_loss --> Total loss \n",
    "\n",
    "        # 3. optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. optimizer step\n",
    "        optimizer.step()\n",
    "        #we are updating our model's parameters once per batch rather than waiting for it to see the whole dataset with every batch\n",
    " \n",
    "\n",
    "        # Print out what's happening\n",
    "        \n",
    "        if batch %400 == 0:\n",
    "            print(f\" Looked at {batch * len(X)}/ {len(train_dataloader.dataset)} samples.\")\n",
    "        \n",
    "\n",
    "    # Divide total train loss by length of train dataloader\n",
    "    train_loss /=len(train_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "    ### Testing\n",
    "    test_loss, test_acc = 0,0\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in test_dataloader:\n",
    "\n",
    "           # 1. Forward pass\n",
    "            test_pred = model_0(X_test) # X_test batch in dataloader\n",
    "\n",
    "            # 2. Calculate the loss accumulatively\n",
    "            test_loss += loss_fn(test_pred, y_test)\n",
    "\n",
    "            # 3. Calculate accuracy\n",
    "            test_acc += accuracy_fn(y_true = y_test, y_pred = test_pred.argmax(dim =1))\n",
    "        \n",
    "        # Calculate the test loss avg per batch\n",
    "        test_loss /= len(test_dataloader)\n",
    "\n",
    "        # Calculate the test acc average per batch\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "\n",
    "    # Print out what's happening\n",
    "    print(f\" \\nTrain loss: {train_loss:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "# Calculate training time\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(start = train_time_start_on_gpu,\n",
    "                                           end = train_time_end_on_cpu,\n",
    "                                           device = str(next(model_0.parameters()).device))\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f40c84-6108-4f27-8704-a5f36fc29be0",
   "metadata": {},
   "source": [
    "# Make predictions and get Model 0 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b518f0c0-9fc9-481a-859f-9d7447e85ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c980d5b20bb340b58b13339ee423fa54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV0',\n",
       " 'model_loss': 0.5136752128601074,\n",
       " 'model_acc': 81.9988019169329}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def eval_mode(model: torch.nn.Module,\n",
    "             data_loader: torch.utils.data.DataLoader,\n",
    "             loss_fn: torch.nn.Module,\n",
    "             accuracy_fn):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting the data loader\"\"\"\n",
    "    loss,acc = 0,0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X,y in tqdm(data_loader):\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Accumulate the loss and acc values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y,\n",
    "                              y_pred = y_pred.argmax(dim=1))\n",
    "\n",
    "        #scale loss and acc to find the average loss/acc per batch\n",
    "    loss=loss /len(data_loader)\n",
    "    acc  = acc/ len(data_loader)\n",
    "\n",
    "\n",
    "    return {\"model_name\": model.__class__.__name__,\n",
    "           \"model_loss\": loss.item(),\n",
    "           \"model_acc\":acc}\n",
    "            \n",
    "    #calculate model_0 results on test dataset\n",
    "model_0_results  = eval_mode(model= model_0,\n",
    "                             data_loader = test_dataloader,\n",
    "                             loss_fn = loss_fn,\n",
    "                             accuracy_fn = accuracy_fn)\n",
    "\n",
    "model_0_results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2350fc4-b260-4785-a6d7-dbdb212959d9",
   "metadata": {},
   "source": [
    "# A comparatively complex Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0503a095-2bf5-45a5-a4fb-63532b6237f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 0 \n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size: int,\n",
    "                 hidden_unit: int,\n",
    "                 output_size: int):\n",
    "        super().__init__()\n",
    "    \n",
    "        self.model_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features = input_size,\n",
    "                      out_features = hidden_unit),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features = hidden_unit,\n",
    "                     out_features = output_size)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model_stack(x)\n",
    "\n",
    "model_01 = FashionMNISTModelV1(input_size = 784,\n",
    "                              hidden_unit=50,\n",
    "                              output_size=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bcd6ef-e2a7-422f-b713-62b8b9504287",
   "metadata": {},
   "source": [
    "## Setup Loss, Optimizer, and Evaluation Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5f154c5-bf3d-493d-9dc2-a6ee3c83f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "loss_fn  = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model_01.parameters(),\n",
    "                            lr = 0.01)\n",
    "\n",
    "# Evaluation Matrix\n",
    "from helper_functions import accuracy_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450d7914-8873-4bff-a853-146104e37b17",
   "metadata": {},
   "source": [
    "# Training & Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b627dd78-10bc-4b34-b821-979ecdf69199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning our training loop into a functio\n",
    "def training_loop(\n",
    "                 model: torch.nn.Module,\n",
    "                 train_data: torch.utils.data.DataLoader,#unit of train_data is batch\n",
    "                 Loss: torch.nn.Module,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 accuracy_fn,\n",
    "                 device = device):\n",
    "\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    train_loss,train_acc = 0,0\n",
    "    #segment the batch\n",
    "    \n",
    "    for batch,(X_train,y_train) in enumerate(train_data):\n",
    "        X_train,y_train = X_train.to(device),y_train.to(device)\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(X_train)\n",
    "\n",
    "        # 2. Loss Calculation\n",
    "        loss = Loss(y_pred,y_train)\n",
    "\n",
    "        train_loss +=loss\n",
    "\n",
    "        acc = accuracy_fn(y_train,\n",
    "                          y_pred.argmax(dim =1))\n",
    "        train_acc +=acc\n",
    "        # 3. Set the gradient zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Backward Pass\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizing step\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    train_loss /=len(train_data)\n",
    "    train_acc /=len(train_data)\n",
    "\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy {train_acc:.5f}\")\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8630a53-8039-45e6-8791-49bbd3f7bd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Loop\n",
    "\n",
    "def testing_loop(model: torch.nn.Module,\n",
    "                test_data: torch.utils.data.DataLoader,\n",
    "                Loss: torch.nn.Module,\n",
    "                accuracy_fn,\n",
    "                device = device):\n",
    "\n",
    "    \n",
    "    test_loss,test_acc = 0,0\n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for X_test,y_test in test_data:\n",
    "            X_test,y_test = X_test.to(device),y_test.to(device)\n",
    "\n",
    "            # 1. Forward Pass\n",
    "            y_test_pred = model(X_test)\n",
    "\n",
    "            # 2. Calculate loss\n",
    "            loss = Loss(y_test_pred, y_test)\n",
    "            test_loss +=loss\n",
    "            acc = accuracy_fn(y_test,\n",
    "                             y_test_pred.argmax(dim = 1))\n",
    "            test_acc +=acc\n",
    "\n",
    "        avg_test_loss = test_loss/len(test_data)\n",
    "        avg_acc = test_acc/len(test_data)\n",
    "        print(f\"Avg test Loss: {avg_test_loss:.4f} | Avg accuracy: {avg_acc:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "451998cc-26cc-44d8-9016-f9498a231f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04dafb004c2a406798edb03d551c87ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0.........\n",
      "Train loss: 0.52297 | Train accuracy 81.36500\n",
      "Avg test Loss: 0.4453 | Avg accuracy: 84.2153\n",
      "Epoch: 1.........\n",
      "Train loss: 0.44421 | Train accuracy 84.13167\n",
      "Avg test Loss: 0.4421 | Avg accuracy: 84.2951\n",
      "Epoch: 2.........\n",
      "Train loss: 0.42250 | Train accuracy 84.85500\n",
      "Avg test Loss: 0.4976 | Avg accuracy: 82.4481\n",
      "Train time on mps: 31.62752024999645 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "#measure time\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "#set epochs \n",
    "epochs = 3\n",
    "\n",
    "# Create a optimization and evaluation loop using train_step() and test_step()\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}.........\")\n",
    "    training_loop(model= model_01,\n",
    "                  train_data=train_dataloader,\n",
    "                  Loss = loss_fn,\n",
    "                  optimizer = optimizer\n",
    "                 )\n",
    "    testing_loop(model = model_01,\n",
    "                test_data=test_dataloader,\n",
    "                Loss = loss_fn\n",
    "                )\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_1 = print_train_time(start = train_time_start_on_gpu,\n",
    "                                           end = train_time_end_on_gpu,\n",
    "                                           device = device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d762e6-ea6f-4c2e-870e-c5f93cba8670",
   "metadata": {},
   "source": [
    "> **Note:** Sometimes, depending on your data/hardware you might find that your model trains\n",
    "faster on CPU than GPU\n",
    "\n",
    ">\n",
    "> Why is this?\n",
    ">\n",
    "> 1. It could be that the overhead for copying data/model to and from the GPU outweighs the\n",
    "compute benefits offered by the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ab050f-9afd-4a4a-a423-1bb668c3fb04",
   "metadata": {},
   "source": [
    "# Get model_1 results dictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9572cc34-257d-42d3-82ea-c174adfdeb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation loop\n",
    "def eval_mode(model: torch.nn.Module,\n",
    "             data_loader: torch.utils.data.DataLoader,\n",
    "             loss_fn: torch.nn.Module,\n",
    "             accuracy_fn,\n",
    "             device = device):\n",
    "    \"\"\"Returns a dictionary containing the results of model predicting the data loader\"\"\"\n",
    "    loss,acc = 0,0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X,y in tqdm(data_loader):\n",
    "            X,y = X.to(device),y.to(device)\n",
    "            y_pred = model(X)\n",
    "\n",
    "            # Accumulate the loss and acc values per batch\n",
    "            loss += loss_fn(y_pred, y)\n",
    "            acc += accuracy_fn(y_true=y,\n",
    "                              y_pred = y_pred.argmax(dim=1))\n",
    "\n",
    "        #scale loss and acc to find the average loss/acc per batch\n",
    "    loss=loss /len(data_loader)\n",
    "    acc  = acc/ len(data_loader)\n",
    "\n",
    "\n",
    "    return {\"model_name\": model.__class__.__name__,\n",
    "           \"model_loss\": loss.item(),\n",
    "           \"model_acc\":acc}\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c40f30c3-a517-4755-bb9f-3a59be2e3952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e6f9ff36d745559786505f2c6e7a40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation_model_1 = eval_mode(model = model_01,\n",
    "                              data_loader=test_dataloader,\n",
    "                              loss_fn=loss_fn,\n",
    "                              accuracy_fn=accuracy_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "820bf6a8-d8cb-422b-8912-897305839012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'FashionMNISTModelV1',\n",
       " 'model_loss': 0.4975889027118683,\n",
       " 'model_acc': 82.44808306709265}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bab187b-b4a4-4db3-a3d0-76195ef5b215",
   "metadata": {},
   "source": [
    "## Building a Convolutional Neural Network\n",
    "\n",
    "* CNN's are also known as ConvNets.\n",
    "* CNN's are known for their capabilities to find patterns in visual data.\n",
    "* More details --> see this website: https://poloclub.github.io/cnn-explainer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b636233-f1aa-447f-9925-49147319c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a conbolutional neural network\n",
    "\n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    '''\n",
    "    Model architecture that replicates the TinyVGG\n",
    "    model from CNN explainer website.\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "\n",
    "        super().__init__()\n",
    "        # Write some conv blocks(blocks are comprised of some layers)\n",
    "        # Convolutional architecture contains a number of conv blocks\n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                     out_channels=hidden_units,\n",
    "                     kernel_size=3, #kernel could be int or tupple; like (3,3)\n",
    "                     stride = 1,\n",
    "                     padding =1), #values we can set ourselves in out NN's are called hyperparameters\n",
    "            \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = hidden_units,\n",
    "                     out_channels = hidden_units,\n",
    "                     kernel_size= 3,\n",
    "                     stride = 1,\n",
    "                     padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                     out_channels=hidden_units,\n",
    "                     kernel_size=3, #kernel could be int or tupple; like (3,3)\n",
    "                     stride = 1,\n",
    "                     padding =1), #values we can set ourselves in out NN's are called hyperparameters\n",
    "            \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels = hidden_units,\n",
    "                     out_channels = hidden_units,\n",
    "                     kernel_size= 3,\n",
    "                     stride = 1,\n",
    "                     padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=hidden_units*7*7,\n",
    "                     out_features=output_shape)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7835ac33-d110-476c-8677-cdbf2309e5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model_02 = FashionMNISTModelV2(input_shape=1,\n",
    "                              hidden_units=10,\n",
    "                              output_shape=len(class_names)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c277320a-f9e1-4e1c-9a5e-9ff836c30224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample image, and pass it through the model\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cd4cfd2f-8d11-45fc-b411-0c0201dc9dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of first Conv_block_1: torch.Size([1, 10, 14, 14])\n",
      "Output of first Conv_block_2: torch.Size([1, 10, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "sample_image = torch.randn(size = (1,28,28))\n",
    "\n",
    "# Pass the image through the model\n",
    "output = model_02(sample_image.unsqueeze(dim=0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "71991934-5ea9-4081-8f68-1c249bb92150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([32, 3, 64, 64])\n",
      "Test image shape: torch.Size([3, 64, 64])\n",
      "Test image:\n",
      "tensor([[[ 1.9269,  1.4873,  0.9007,  ...,  1.8446, -1.1845,  1.3835],\n",
      "         [ 1.4451,  0.8564,  2.2181,  ...,  0.3399,  0.7200,  0.4114],\n",
      "         [ 1.9312,  1.0119, -1.4364,  ..., -0.5558,  0.7043,  0.7099],\n",
      "         ...,\n",
      "         [-0.5610, -0.4830,  0.4770,  ..., -0.2713, -0.9537, -0.6737],\n",
      "         [ 0.3076, -0.1277,  0.0366,  ..., -2.0060,  0.2824, -0.8111],\n",
      "         [-1.5486,  0.0485, -0.7712,  ..., -0.1403,  0.9416, -0.0118]],\n",
      "\n",
      "        [[-0.5197,  1.8524,  1.8365,  ...,  0.8935, -1.5114, -0.8515],\n",
      "         [ 2.0818,  1.0677, -1.4277,  ...,  1.6612, -2.6223, -0.4319],\n",
      "         [-0.1010, -0.4388, -1.9775,  ...,  0.2106,  0.2536, -0.7318],\n",
      "         ...,\n",
      "         [ 0.2779,  0.7342, -0.3736,  ..., -0.4601,  0.1815,  0.1850],\n",
      "         [ 0.7205, -0.2833,  0.0937,  ..., -0.1002, -2.3609,  2.2465],\n",
      "         [-1.3242, -0.1973,  0.2920,  ...,  0.5409,  0.6940,  1.8563]],\n",
      "\n",
      "        [[-0.7978,  1.0261,  1.1465,  ...,  1.2134,  0.9354, -0.0780],\n",
      "         [-1.4647, -1.9571,  0.1017,  ..., -1.9986, -0.7409,  0.7011],\n",
      "         [-1.3938,  0.8466, -1.7191,  ..., -1.1867,  0.1320,  0.3407],\n",
      "         ...,\n",
      "         [ 0.8206, -0.3745,  1.2499,  ..., -0.0676,  0.0385,  0.6335],\n",
      "         [-0.5589, -0.3393,  0.2347,  ...,  2.1181,  2.4569,  1.3083],\n",
      "         [-0.4092,  1.5199,  0.2401,  ..., -0.2558,  0.7870,  0.9924]]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "#create a batch of image\n",
    "images = torch.randn(size =(32,3,64,64))\n",
    "\n",
    "test_image = images[0]\n",
    "\n",
    "print(f\"Image batch shape: {images.shape}\")\n",
    "print(f\"Test image shape: {test_image.shape}\")\n",
    "print(f\"Test image:\\n{test_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "389e620f-7e95-4b3b-be9c-41739150b4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('conv_block1.0.weight',\n",
       "              tensor([[[[ 0.2548,  0.2767, -0.0781],\n",
       "                        [ 0.3062, -0.0730,  0.0673],\n",
       "                        [-0.1623,  0.1958,  0.2938]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2445,  0.2897,  0.0624],\n",
       "                        [ 0.2463,  0.0451,  0.1607],\n",
       "                        [-0.0471,  0.2570,  0.0493]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1556,  0.0850, -0.1536],\n",
       "                        [-0.0391, -0.1354,  0.2211],\n",
       "                        [-0.2631, -0.1537, -0.0941]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2004,  0.0315, -0.3292],\n",
       "                        [ 0.3010, -0.2832,  0.2573],\n",
       "                        [ 0.0555, -0.1082,  0.2060]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0520,  0.2693,  0.0364],\n",
       "                        [-0.1051,  0.0896, -0.0904],\n",
       "                        [ 0.1403,  0.2976,  0.1927]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1457,  0.1924,  0.0596],\n",
       "                        [ 0.1693, -0.2032, -0.3300],\n",
       "                        [-0.1288, -0.2557,  0.2735]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0960,  0.1381,  0.1054],\n",
       "                        [-0.0058,  0.2609, -0.2368],\n",
       "                        [ 0.0210, -0.2275,  0.1028]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1148,  0.1021, -0.0694],\n",
       "                        [ 0.2765, -0.1976, -0.1988],\n",
       "                        [-0.1988,  0.2998,  0.1111]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3208, -0.2751, -0.3306],\n",
       "                        [-0.2608, -0.2242,  0.1350],\n",
       "                        [ 0.1194,  0.2770, -0.1721]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2272,  0.1769, -0.1347],\n",
       "                        [ 0.2023, -0.0791,  0.1907],\n",
       "                        [-0.2590, -0.1682,  0.1016]]]], device='mps:0')),\n",
       "             ('conv_block1.0.bias',\n",
       "              tensor([ 0.0705, -0.0850,  0.1987,  0.2266, -0.2417, -0.1780,  0.3052, -0.1125,\n",
       "                      -0.1182, -0.3225], device='mps:0')),\n",
       "             ('conv_block1.2.weight',\n",
       "              tensor([[[[-0.0604,  0.0263, -0.0139],\n",
       "                        [-0.0765,  0.0025, -0.0720],\n",
       "                        [-0.0894, -0.0580, -0.0923]],\n",
       "              \n",
       "                       [[-0.0671,  0.1054,  0.0199],\n",
       "                        [ 0.0325, -0.0983, -0.0692],\n",
       "                        [-0.0351,  0.0165, -0.0928]],\n",
       "              \n",
       "                       [[-0.0454, -0.0631,  0.0003],\n",
       "                        [-0.0392, -0.0073, -0.0714],\n",
       "                        [-0.0724, -0.0615, -0.0361]],\n",
       "              \n",
       "                       [[-0.0832,  0.0884, -0.0209],\n",
       "                        [ 0.0907,  0.0328, -0.0893],\n",
       "                        [ 0.0729, -0.0290, -0.0404]],\n",
       "              \n",
       "                       [[-0.0875, -0.1048,  0.0302],\n",
       "                        [-0.0230,  0.0410, -0.0865],\n",
       "                        [ 0.0783, -0.0774, -0.0182]],\n",
       "              \n",
       "                       [[ 0.0220,  0.0544,  0.0851],\n",
       "                        [ 0.0960, -0.0836,  0.0265],\n",
       "                        [-0.0453, -0.0116, -0.0789]],\n",
       "              \n",
       "                       [[ 0.0960, -0.0774,  0.0563],\n",
       "                        [ 0.0370,  0.0343, -0.0570],\n",
       "                        [ 0.0958,  0.0232,  0.0136]],\n",
       "              \n",
       "                       [[-0.0929,  0.0442, -0.0158],\n",
       "                        [-0.0483,  0.0905,  0.0235],\n",
       "                        [-0.0583, -0.0534, -0.0050]],\n",
       "              \n",
       "                       [[ 0.0589, -0.0269, -0.0601],\n",
       "                        [-0.0361, -0.0787,  0.0376],\n",
       "                        [ 0.0816, -0.0992,  0.0245]],\n",
       "              \n",
       "                       [[ 0.0545,  0.0191, -0.0375],\n",
       "                        [ 0.0550,  0.0554,  0.0394],\n",
       "                        [-0.0185, -0.0279,  0.0113]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0186, -0.0314,  0.0674],\n",
       "                        [ 0.0906, -0.0104, -0.0236],\n",
       "                        [ 0.0015, -0.0063,  0.0253]],\n",
       "              \n",
       "                       [[ 0.0295, -0.0957, -0.0389],\n",
       "                        [ 0.0888,  0.0411, -0.0052],\n",
       "                        [-0.0636, -0.0645, -0.0944]],\n",
       "              \n",
       "                       [[-0.0344,  0.0356,  0.0672],\n",
       "                        [ 0.0487, -0.0932, -0.0634],\n",
       "                        [-0.0166,  0.1020,  0.0152]],\n",
       "              \n",
       "                       [[-0.0273,  0.0436, -0.0401],\n",
       "                        [-0.0682,  0.0769, -0.0479],\n",
       "                        [-0.0211, -0.1049,  0.0705]],\n",
       "              \n",
       "                       [[ 0.0799,  0.0384, -0.0735],\n",
       "                        [-0.1040, -0.0856,  0.0786],\n",
       "                        [ 0.0506,  0.0887,  0.0552]],\n",
       "              \n",
       "                       [[ 0.0267, -0.0010, -0.0802],\n",
       "                        [-0.0903, -0.0986,  0.0432],\n",
       "                        [-0.0518, -0.0212, -0.0607]],\n",
       "              \n",
       "                       [[-0.0192, -0.0742, -0.0689],\n",
       "                        [ 0.0350, -0.0313,  0.0651],\n",
       "                        [-0.0338, -0.0773, -0.0186]],\n",
       "              \n",
       "                       [[-0.0511, -0.0322, -0.1003],\n",
       "                        [ 0.0590, -0.0734,  0.0530],\n",
       "                        [ 0.0478,  0.0753, -0.0809]],\n",
       "              \n",
       "                       [[ 0.0758, -0.0498,  0.0391],\n",
       "                        [ 0.0990, -0.0149, -0.0008],\n",
       "                        [-0.0243, -0.0880,  0.0506]],\n",
       "              \n",
       "                       [[-0.1046,  0.0654,  0.0789],\n",
       "                        [ 0.0997, -0.0249, -0.0866],\n",
       "                        [ 0.0237,  0.0582, -0.1049]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0239, -0.0632, -0.0092],\n",
       "                        [-0.0519, -0.0431, -0.0335],\n",
       "                        [-0.1002,  0.0865,  0.0884]],\n",
       "              \n",
       "                       [[-0.0165, -0.0120, -0.0430],\n",
       "                        [-0.0952, -0.1026,  0.0392],\n",
       "                        [-0.0579, -0.0678, -0.0082]],\n",
       "              \n",
       "                       [[-0.0351, -0.0341,  0.0034],\n",
       "                        [-0.0224, -0.0363, -0.0505],\n",
       "                        [-0.0858,  0.0884, -0.0422]],\n",
       "              \n",
       "                       [[ 0.0279, -0.0366,  0.0086],\n",
       "                        [ 0.0983,  0.0486, -0.0913],\n",
       "                        [ 0.0418,  0.1001,  0.0277]],\n",
       "              \n",
       "                       [[ 0.0707,  0.1039, -0.0162],\n",
       "                        [ 0.0219, -0.0733, -0.0217],\n",
       "                        [ 0.0781,  0.0540, -0.0667]],\n",
       "              \n",
       "                       [[-0.0845, -0.0720, -0.1040],\n",
       "                        [-0.0813, -0.0261,  0.0711],\n",
       "                        [ 0.0176, -0.0802, -0.0846]],\n",
       "              \n",
       "                       [[ 0.0524, -0.0784, -0.0130],\n",
       "                        [ 0.0506, -0.0488, -0.0115],\n",
       "                        [-0.0092, -0.0249, -0.0534]],\n",
       "              \n",
       "                       [[-0.0940, -0.0852, -0.0564],\n",
       "                        [ 0.1018, -0.0509, -0.0708],\n",
       "                        [ 0.0256,  0.0291,  0.0578]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0587, -0.1045],\n",
       "                        [ 0.0093,  0.0639, -0.0097],\n",
       "                        [-0.0621,  0.1005, -0.0394]],\n",
       "              \n",
       "                       [[-0.0600, -0.0950,  0.0047],\n",
       "                        [ 0.0467,  0.0233,  0.0208],\n",
       "                        [-0.0799, -0.0984,  0.0019]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0961,  0.0608, -0.0614],\n",
       "                        [-0.0137, -0.0777, -0.0509],\n",
       "                        [ 0.0191,  0.0574,  0.0873]],\n",
       "              \n",
       "                       [[-0.0968,  0.0705, -0.0743],\n",
       "                        [ 0.0395,  0.0892,  0.0015],\n",
       "                        [ 0.0959, -0.0898, -0.0403]],\n",
       "              \n",
       "                       [[ 0.0615, -0.0230, -0.0216],\n",
       "                        [-0.0439,  0.0727,  0.0517],\n",
       "                        [ 0.0338, -0.0592, -0.0856]],\n",
       "              \n",
       "                       [[ 0.0114,  0.0312, -0.0487],\n",
       "                        [-0.0295,  0.0712,  0.0084],\n",
       "                        [ 0.0048, -0.0259, -0.0955]],\n",
       "              \n",
       "                       [[-0.0991, -0.0504, -0.0536],\n",
       "                        [ 0.0328, -0.0307, -0.0412],\n",
       "                        [ 0.1005,  0.0367,  0.0751]],\n",
       "              \n",
       "                       [[-0.0510, -0.0431,  0.0387],\n",
       "                        [-0.0702, -0.0689, -0.0051],\n",
       "                        [-0.0386, -0.0790,  0.0625]],\n",
       "              \n",
       "                       [[ 0.0848,  0.0171, -0.0184],\n",
       "                        [-0.0976, -0.0384,  0.0268],\n",
       "                        [ 0.0497, -0.0133, -0.0417]],\n",
       "              \n",
       "                       [[ 0.0587, -0.0839,  0.0666],\n",
       "                        [-0.0409,  0.0016, -0.0208],\n",
       "                        [ 0.0128, -0.0319,  0.0766]],\n",
       "              \n",
       "                       [[-0.0027,  0.0823,  0.1013],\n",
       "                        [-0.0514, -0.0769,  0.0846],\n",
       "                        [ 0.0826, -0.0805, -0.0081]],\n",
       "              \n",
       "                       [[-0.1039, -0.0863,  0.0204],\n",
       "                        [ 0.0280,  0.0223, -0.0287],\n",
       "                        [ 0.0972,  0.0151, -0.0622]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0060,  0.0253,  0.0369],\n",
       "                        [-0.0745,  0.0395, -0.0539],\n",
       "                        [-0.0876, -0.0576,  0.1017]],\n",
       "              \n",
       "                       [[ 0.0901,  0.0944,  0.0619],\n",
       "                        [ 0.0796, -0.0141, -0.0580],\n",
       "                        [ 0.0527, -0.0546, -0.0711]],\n",
       "              \n",
       "                       [[-0.0337,  0.0221,  0.0543],\n",
       "                        [-0.0409, -0.0620,  0.0142],\n",
       "                        [-0.0621, -0.0686,  0.0549]],\n",
       "              \n",
       "                       [[-0.0177,  0.0963,  0.1025],\n",
       "                        [ 0.0315,  0.0363,  0.0243],\n",
       "                        [ 0.0017, -0.0077,  0.0014]],\n",
       "              \n",
       "                       [[ 0.0394,  0.0980, -0.0273],\n",
       "                        [-0.0446, -0.0255, -0.0509],\n",
       "                        [ 0.0179,  0.0787,  0.0824]],\n",
       "              \n",
       "                       [[ 0.0484, -0.0776, -0.0566],\n",
       "                        [-0.0232, -0.0194,  0.0087],\n",
       "                        [-0.0968,  0.0328, -0.0804]],\n",
       "              \n",
       "                       [[-0.0667, -0.0876,  0.0918],\n",
       "                        [-0.0998,  0.0795, -0.0035],\n",
       "                        [-0.0123,  0.0659, -0.0097]],\n",
       "              \n",
       "                       [[ 0.0661,  0.0762, -0.0915],\n",
       "                        [ 0.0406,  0.0199,  0.0227],\n",
       "                        [ 0.0154,  0.0288, -0.0507]],\n",
       "              \n",
       "                       [[-0.0135,  0.1002,  0.0708],\n",
       "                        [-0.0040, -0.0991,  0.0046],\n",
       "                        [-0.0718,  0.0857, -0.0640]],\n",
       "              \n",
       "                       [[-0.0076, -0.0234,  0.0188],\n",
       "                        [ 0.0992,  0.0100,  0.0610],\n",
       "                        [ 0.0818,  0.0851, -0.0364]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0236,  0.0508, -0.0288],\n",
       "                        [ 0.0494, -0.0230, -0.0715],\n",
       "                        [ 0.0429,  0.0162,  0.0470]],\n",
       "              \n",
       "                       [[ 0.1047,  0.0720,  0.0999],\n",
       "                        [ 0.0056, -0.0907, -0.0739],\n",
       "                        [-0.0655, -0.0929, -0.0528]],\n",
       "              \n",
       "                       [[-0.0970, -0.0973, -0.0630],\n",
       "                        [-0.1039, -0.0647,  0.0402],\n",
       "                        [ 0.0879, -0.0314, -0.0307]],\n",
       "              \n",
       "                       [[ 0.0563, -0.0520, -0.0498],\n",
       "                        [ 0.0649, -0.0918,  0.0129],\n",
       "                        [ 0.0931,  0.0181,  0.0287]],\n",
       "              \n",
       "                       [[-0.0614, -0.0015,  0.0058],\n",
       "                        [ 0.0259,  0.0410,  0.0916],\n",
       "                        [-0.0805,  0.0032, -0.0527]],\n",
       "              \n",
       "                       [[-0.0834, -0.0084, -0.0928],\n",
       "                        [ 0.0736,  0.0122, -0.0568],\n",
       "                        [ 0.0551, -0.0998, -0.0408]],\n",
       "              \n",
       "                       [[-0.0205, -0.0896, -0.0670],\n",
       "                        [-0.0172,  0.0800,  0.1018],\n",
       "                        [ 0.0671, -0.0629, -0.0690]],\n",
       "              \n",
       "                       [[ 0.0920,  0.0373,  0.0028],\n",
       "                        [ 0.0143, -0.0847, -0.0352],\n",
       "                        [ 0.1015, -0.0260, -0.0053]],\n",
       "              \n",
       "                       [[-0.0875, -0.0590, -0.0022],\n",
       "                        [-0.0655, -0.0131,  0.0429],\n",
       "                        [-0.1031,  0.0313, -0.0697]],\n",
       "              \n",
       "                       [[-0.0514,  0.0405,  0.0838],\n",
       "                        [-0.0288, -0.0433, -0.0953],\n",
       "                        [-0.0544, -0.0923, -0.0241]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0215, -0.0988,  0.0920],\n",
       "                        [ 0.0661, -0.1032, -0.0503],\n",
       "                        [ 0.0344, -0.0217, -0.0115]],\n",
       "              \n",
       "                       [[-0.0476,  0.0847, -0.0589],\n",
       "                        [ 0.0874,  0.0068,  0.0212],\n",
       "                        [ 0.0822, -0.0174, -0.0600]],\n",
       "              \n",
       "                       [[-0.0170,  0.0855, -0.0782],\n",
       "                        [ 0.0239, -0.1036,  0.0553],\n",
       "                        [ 0.0389,  0.0045,  0.0452]],\n",
       "              \n",
       "                       [[ 0.0001,  0.0583, -0.0834],\n",
       "                        [-0.0155,  0.0468,  0.1050],\n",
       "                        [ 0.0537, -0.0767,  0.0811]],\n",
       "              \n",
       "                       [[-0.0235, -0.0225, -0.0958],\n",
       "                        [-0.0166,  0.0746,  0.0147],\n",
       "                        [-0.0614,  0.0324, -0.0338]],\n",
       "              \n",
       "                       [[ 0.0962, -0.0915, -0.0333],\n",
       "                        [-0.1018, -0.0415,  0.0332],\n",
       "                        [ 0.1015,  0.0177,  0.1033]],\n",
       "              \n",
       "                       [[ 0.0206,  0.0609,  0.0845],\n",
       "                        [ 0.0881, -0.0590,  0.0969],\n",
       "                        [ 0.0639, -0.0493, -0.0503]],\n",
       "              \n",
       "                       [[-0.0884,  0.0265, -0.0854],\n",
       "                        [ 0.0445,  0.0333, -0.0916],\n",
       "                        [ 0.0287, -0.0086,  0.0482]],\n",
       "              \n",
       "                       [[ 0.0605, -0.1048,  0.0967],\n",
       "                        [ 0.0884,  0.0419, -0.0963],\n",
       "                        [-0.0377, -0.0305, -0.0271]],\n",
       "              \n",
       "                       [[ 0.0594,  0.0383,  0.0835],\n",
       "                        [-0.0395,  0.0355,  0.0375],\n",
       "                        [-0.0878, -0.1022, -0.0547]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0722, -0.0992, -0.0918],\n",
       "                        [ 0.0591,  0.0569,  0.0867],\n",
       "                        [-0.0796, -0.0771,  0.0541]],\n",
       "              \n",
       "                       [[ 0.0917,  0.0631,  0.0165],\n",
       "                        [ 0.0347,  0.1000, -0.0680],\n",
       "                        [-0.0479,  0.0737, -0.0721]],\n",
       "              \n",
       "                       [[-0.0581,  0.0769,  0.0333],\n",
       "                        [ 0.0341, -0.0447, -0.0015],\n",
       "                        [ 0.0965, -0.0633,  0.0008]],\n",
       "              \n",
       "                       [[ 0.0501, -0.0728,  0.1024],\n",
       "                        [-0.0527, -0.0253, -0.0285],\n",
       "                        [-0.0687, -0.1034,  0.0594]],\n",
       "              \n",
       "                       [[ 0.0280, -0.0987, -0.0678],\n",
       "                        [ 0.1042,  0.0403,  0.0423],\n",
       "                        [-0.0631, -0.0462, -0.0159]],\n",
       "              \n",
       "                       [[-0.0193, -0.0722,  0.0087],\n",
       "                        [ 0.0105, -0.0133,  0.0146],\n",
       "                        [-0.0418,  0.0274,  0.0398]],\n",
       "              \n",
       "                       [[-0.0555, -0.1045,  0.0552],\n",
       "                        [ 0.0251, -0.0536,  0.1016],\n",
       "                        [-0.0477,  0.0712,  0.0535]],\n",
       "              \n",
       "                       [[-0.0884,  0.0680, -0.0969],\n",
       "                        [-0.0584, -0.0176, -0.0711],\n",
       "                        [ 0.1030, -0.0211,  0.0419]],\n",
       "              \n",
       "                       [[-0.0941,  0.0607, -0.0328],\n",
       "                        [-0.0802,  0.0154,  0.0511],\n",
       "                        [ 0.0912, -0.0644, -0.0519]],\n",
       "              \n",
       "                       [[ 0.0203,  0.0286,  0.0405],\n",
       "                        [ 0.0579, -0.0239,  0.0586],\n",
       "                        [ 0.0777, -0.0275,  0.0750]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0515,  0.0930, -0.0599],\n",
       "                        [-0.0521, -0.0305,  0.0053],\n",
       "                        [ 0.0633, -0.0602,  0.0528]],\n",
       "              \n",
       "                       [[-0.0378,  0.0637, -0.0050],\n",
       "                        [-0.0923, -0.0580, -0.0763],\n",
       "                        [ 0.0523, -0.0707, -0.0088]],\n",
       "              \n",
       "                       [[ 0.0227, -0.0578,  0.0304],\n",
       "                        [-0.1029, -0.0754, -0.0955],\n",
       "                        [-0.0319, -0.0384,  0.0151]],\n",
       "              \n",
       "                       [[-0.0195,  0.0496,  0.0966],\n",
       "                        [ 0.0378, -0.0415, -0.0987],\n",
       "                        [ 0.0382, -0.0522,  0.0536]],\n",
       "              \n",
       "                       [[ 0.0705,  0.0407,  0.0989],\n",
       "                        [ 0.1001,  0.0223, -0.0768],\n",
       "                        [ 0.0942, -0.0500, -0.0498]],\n",
       "              \n",
       "                       [[ 0.0882,  0.0817,  0.0318],\n",
       "                        [ 0.0066, -0.0887, -0.0109],\n",
       "                        [ 0.1011,  0.0268,  0.0090]],\n",
       "              \n",
       "                       [[-0.0219, -0.0368,  0.0628],\n",
       "                        [ 0.0065,  0.0686, -0.0187],\n",
       "                        [ 0.0461,  0.0435,  0.0168]],\n",
       "              \n",
       "                       [[ 0.0662,  0.0661,  0.0977],\n",
       "                        [ 0.0810, -0.0270, -0.0892],\n",
       "                        [ 0.0193, -0.0009, -0.0275]],\n",
       "              \n",
       "                       [[-0.0177,  0.0050,  0.0769],\n",
       "                        [ 0.0329, -0.0374, -0.0433],\n",
       "                        [-0.0261, -0.0407,  0.0948]],\n",
       "              \n",
       "                       [[ 0.0558,  0.0952,  0.0003],\n",
       "                        [ 0.0213,  0.0366, -0.0998],\n",
       "                        [ 0.0094, -0.0071, -0.0591]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0818,  0.0933,  0.0857],\n",
       "                        [ 0.0489,  0.1006, -0.0428],\n",
       "                        [-0.0182,  0.0399, -0.0174]],\n",
       "              \n",
       "                       [[-0.0207, -0.0871,  0.0283],\n",
       "                        [-0.0637,  0.0038,  0.1028],\n",
       "                        [-0.0324, -0.0332,  0.0636]],\n",
       "              \n",
       "                       [[-0.0388, -0.0091,  0.0984],\n",
       "                        [-0.0432, -0.0754, -0.0590],\n",
       "                        [-0.0292, -0.0500, -0.0547]],\n",
       "              \n",
       "                       [[ 0.0426,  0.0179, -0.0337],\n",
       "                        [-0.0819, -0.0332, -0.0445],\n",
       "                        [-0.0343, -0.0951,  0.0227]],\n",
       "              \n",
       "                       [[-0.0774, -0.0821, -0.0861],\n",
       "                        [ 0.0440, -0.0635, -0.0435],\n",
       "                        [ 0.0826,  0.0560,  0.0604]],\n",
       "              \n",
       "                       [[-0.1001, -0.0756, -0.0398],\n",
       "                        [ 0.0871,  0.0108, -0.0788],\n",
       "                        [ 0.0007, -0.0819, -0.0231]],\n",
       "              \n",
       "                       [[-0.0290,  0.0912,  0.0326],\n",
       "                        [-0.0184,  0.0178, -0.0304],\n",
       "                        [ 0.0414,  0.0417,  0.0283]],\n",
       "              \n",
       "                       [[-0.0411,  0.0899, -0.0152],\n",
       "                        [-0.0410,  0.0660,  0.0859],\n",
       "                        [ 0.1049,  0.0312, -0.0359]],\n",
       "              \n",
       "                       [[ 0.0535,  0.0904, -0.1034],\n",
       "                        [-0.0131, -0.0719,  0.0196],\n",
       "                        [ 0.0436, -0.0218, -0.0088]],\n",
       "              \n",
       "                       [[ 0.0474, -0.0177, -0.0885],\n",
       "                        [ 0.0843, -0.0531, -0.0116],\n",
       "                        [ 0.0099, -0.0063, -0.0992]]]], device='mps:0')),\n",
       "             ('conv_block1.2.bias',\n",
       "              tensor([ 0.0484, -0.0479, -0.0547,  0.0252, -0.0550, -0.0487, -0.0355, -0.0396,\n",
       "                      -0.0440, -0.0284], device='mps:0')),\n",
       "             ('conv_block2.0.weight',\n",
       "              tensor([[[[ 2.7393e-02, -8.5299e-02, -6.3802e-02],\n",
       "                        [ 1.5381e-03,  1.4659e-02,  5.8217e-02],\n",
       "                        [-7.4044e-02,  3.3646e-02,  5.9914e-02]],\n",
       "              \n",
       "                       [[ 5.8530e-02, -9.8180e-02, -4.0225e-02],\n",
       "                        [-9.0606e-02, -6.6704e-02,  5.8711e-02],\n",
       "                        [-1.5740e-02,  4.4769e-02, -6.1876e-02]],\n",
       "              \n",
       "                       [[ 1.6018e-02, -6.3758e-02,  5.2693e-02],\n",
       "                        [-4.6104e-02, -2.6432e-02, -9.1456e-02],\n",
       "                        [ 3.4822e-04,  1.0008e-01,  5.1163e-02]],\n",
       "              \n",
       "                       [[-5.6240e-02,  1.4176e-03, -1.1558e-02],\n",
       "                        [-8.4862e-02,  8.2650e-02,  1.6993e-03],\n",
       "                        [ 2.2199e-02, -4.2567e-02, -4.9323e-02]],\n",
       "              \n",
       "                       [[ 1.7381e-02,  3.8971e-02,  2.3643e-02],\n",
       "                        [-5.0801e-02,  1.0234e-01, -1.5517e-02],\n",
       "                        [-6.4554e-02, -4.9301e-02,  1.0377e-01]],\n",
       "              \n",
       "                       [[ 5.0766e-06, -1.4309e-02, -4.3867e-02],\n",
       "                        [-2.7633e-02, -8.8779e-02, -8.3767e-02],\n",
       "                        [ 6.1695e-02,  9.0172e-02,  1.0059e-01]],\n",
       "              \n",
       "                       [[-7.6099e-02,  5.7012e-02, -6.5245e-02],\n",
       "                        [ 6.2883e-02,  7.6058e-02,  8.1573e-02],\n",
       "                        [ 7.5900e-02,  6.5941e-02,  2.0516e-03]],\n",
       "              \n",
       "                       [[ 4.8434e-02, -3.7712e-02,  4.5899e-02],\n",
       "                        [-3.3879e-02, -1.7700e-03, -9.1746e-02],\n",
       "                        [-2.7562e-02, -5.5432e-02, -3.5557e-02]],\n",
       "              \n",
       "                       [[-6.7313e-02, -9.4810e-02,  6.8639e-03],\n",
       "                        [ 6.8408e-02,  9.6001e-02,  6.1512e-02],\n",
       "                        [-5.4638e-02, -1.0425e-01,  3.9983e-02]],\n",
       "              \n",
       "                       [[ 5.9062e-02, -9.0495e-02,  3.7798e-02],\n",
       "                        [ 8.9121e-02,  6.3853e-03, -6.3505e-02],\n",
       "                        [ 8.6423e-02,  4.5011e-02,  6.9802e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.1287e-02,  6.1342e-02, -7.2002e-02],\n",
       "                        [ 1.0430e-01, -4.4662e-02,  6.3516e-02],\n",
       "                        [ 2.1107e-02,  2.7935e-02, -1.6165e-02]],\n",
       "              \n",
       "                       [[ 4.3295e-02, -4.3932e-02, -9.9357e-02],\n",
       "                        [-4.0499e-02,  8.2592e-02, -2.7751e-02],\n",
       "                        [ 3.3132e-02, -3.8973e-02,  7.9073e-02]],\n",
       "              \n",
       "                       [[ 6.3086e-02,  3.7211e-02, -5.3881e-02],\n",
       "                        [-8.6133e-02,  3.9686e-03, -6.1839e-02],\n",
       "                        [ 8.6667e-02, -1.0130e-01,  4.7104e-02]],\n",
       "              \n",
       "                       [[ 1.0508e-01,  5.2792e-02,  3.5942e-02],\n",
       "                        [-1.0142e-01,  1.0139e-01, -1.8030e-02],\n",
       "                        [-9.8495e-02,  1.0406e-01, -4.2894e-02]],\n",
       "              \n",
       "                       [[-7.4575e-03,  9.6479e-02, -7.3070e-02],\n",
       "                        [-7.4576e-02,  1.7141e-02, -1.4109e-02],\n",
       "                        [ 2.4280e-02, -8.8407e-02,  3.1524e-03]],\n",
       "              \n",
       "                       [[-4.6882e-02, -5.1820e-02, -9.6517e-02],\n",
       "                        [ 5.5890e-02,  2.0306e-02, -8.9118e-02],\n",
       "                        [ 8.3648e-02,  3.1794e-02,  1.9560e-02]],\n",
       "              \n",
       "                       [[-6.1890e-02,  1.5896e-02,  1.0157e-01],\n",
       "                        [ 7.2299e-02, -8.2100e-02,  9.6220e-02],\n",
       "                        [ 8.1702e-03,  5.0698e-02,  8.1869e-02]],\n",
       "              \n",
       "                       [[ 8.9862e-02, -8.2170e-02,  9.2303e-02],\n",
       "                        [-7.1591e-02,  7.9021e-03, -7.3656e-02],\n",
       "                        [-2.3109e-02, -4.7901e-03, -1.2611e-02]],\n",
       "              \n",
       "                       [[-1.6652e-02,  8.3137e-03,  1.0398e-01],\n",
       "                        [ 6.1244e-02,  5.8973e-02,  4.2190e-02],\n",
       "                        [ 8.1606e-02, -4.8645e-03,  8.3813e-03]],\n",
       "              \n",
       "                       [[ 2.1693e-02, -9.1931e-02, -8.4913e-02],\n",
       "                        [ 1.2923e-02, -4.1241e-02, -1.9342e-03],\n",
       "                        [-2.4187e-02,  1.6408e-02,  6.8581e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.4958e-02,  8.4418e-02,  8.3227e-02],\n",
       "                        [-8.0901e-02, -8.1400e-02, -8.5284e-02],\n",
       "                        [-5.7766e-02, -4.1033e-02, -7.9341e-03]],\n",
       "              \n",
       "                       [[-2.5635e-02, -5.3258e-02, -3.3488e-02],\n",
       "                        [-3.8131e-02,  1.0341e-01, -3.9068e-02],\n",
       "                        [-7.5473e-02,  4.3818e-02, -6.0886e-03]],\n",
       "              \n",
       "                       [[ 8.0698e-02,  6.5863e-02,  9.6843e-02],\n",
       "                        [-7.7197e-02,  6.7764e-02,  8.8464e-02],\n",
       "                        [-5.2054e-02,  9.6890e-02,  7.9019e-02]],\n",
       "              \n",
       "                       [[ 1.1544e-03,  5.0823e-02, -3.6853e-02],\n",
       "                        [-9.1936e-02,  2.6645e-02,  3.1425e-02],\n",
       "                        [-6.8891e-02,  5.1123e-02, -9.0043e-02]],\n",
       "              \n",
       "                       [[ 9.0718e-02,  1.0208e-01,  2.8699e-02],\n",
       "                        [-6.6137e-02,  5.1300e-02,  1.7963e-02],\n",
       "                        [ 2.8663e-02,  3.4643e-02,  8.0254e-02]],\n",
       "              \n",
       "                       [[-4.5309e-02, -2.3711e-02,  2.8746e-02],\n",
       "                        [ 1.1486e-02,  8.5000e-02, -5.5365e-02],\n",
       "                        [-3.8387e-03,  1.9696e-02, -2.7996e-02]],\n",
       "              \n",
       "                       [[ 7.1859e-02,  1.1530e-02, -9.7422e-02],\n",
       "                        [-1.1420e-02, -4.7809e-02,  1.0243e-02],\n",
       "                        [-1.2250e-02, -1.0456e-01, -1.9208e-02]],\n",
       "              \n",
       "                       [[-1.0096e-02, -3.1083e-02,  9.6848e-02],\n",
       "                        [-2.3000e-02,  6.7717e-02,  2.6112e-02],\n",
       "                        [-8.8979e-02,  2.4770e-02,  8.7356e-02]],\n",
       "              \n",
       "                       [[-6.8948e-02, -6.8134e-02,  1.0318e-01],\n",
       "                        [ 8.4697e-02, -5.8807e-02,  6.3429e-02],\n",
       "                        [-1.3485e-02, -1.0393e-01,  7.9198e-03]],\n",
       "              \n",
       "                       [[ 3.4057e-02, -3.1619e-02,  3.6670e-02],\n",
       "                        [-9.0136e-02,  7.3050e-02,  8.9865e-02],\n",
       "                        [ 5.8130e-02,  1.7866e-02,  3.4716e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.6269e-02, -2.6339e-02, -1.0063e-02],\n",
       "                        [-5.8659e-02, -7.7857e-02,  7.0900e-02],\n",
       "                        [ 7.1535e-02, -9.5731e-02,  3.3542e-02]],\n",
       "              \n",
       "                       [[ 4.2881e-02,  1.0014e-01,  6.0985e-02],\n",
       "                        [ 9.6907e-02, -3.4510e-02,  7.3827e-02],\n",
       "                        [ 8.5740e-02, -9.9541e-02, -8.4613e-02]],\n",
       "              \n",
       "                       [[ 2.1335e-02,  5.7557e-02, -5.2369e-02],\n",
       "                        [ 1.1609e-02, -1.5303e-04,  2.6680e-02],\n",
       "                        [-5.6642e-02,  5.9455e-02,  7.0098e-02]],\n",
       "              \n",
       "                       [[-7.3139e-02,  1.0211e-03,  2.9247e-04],\n",
       "                        [ 3.3849e-02,  9.8198e-02,  3.0913e-02],\n",
       "                        [-2.3951e-02,  9.4672e-02, -4.0112e-02]],\n",
       "              \n",
       "                       [[-3.0608e-02,  7.1969e-03, -8.0270e-02],\n",
       "                        [ 1.1470e-02, -7.1518e-02,  1.0838e-02],\n",
       "                        [ 1.0099e-02,  1.4591e-02, -8.8891e-02]],\n",
       "              \n",
       "                       [[-1.0012e-01,  4.8501e-02,  9.0399e-02],\n",
       "                        [-9.3537e-02,  3.9043e-02, -7.7594e-02],\n",
       "                        [ 6.6082e-03,  9.8068e-02,  7.9965e-02]],\n",
       "              \n",
       "                       [[-7.7069e-02,  6.5203e-02,  5.5057e-02],\n",
       "                        [-1.6168e-04,  1.0211e-01, -4.1866e-02],\n",
       "                        [-2.4530e-02, -5.3275e-02,  1.5168e-02]],\n",
       "              \n",
       "                       [[ 2.7911e-02,  8.3990e-03, -5.9307e-02],\n",
       "                        [-4.7452e-02,  3.5855e-02, -9.2426e-02],\n",
       "                        [-1.6416e-02, -2.3350e-03, -4.2708e-02]],\n",
       "              \n",
       "                       [[ 3.8360e-02,  6.7940e-03,  7.4004e-02],\n",
       "                        [-9.3616e-03, -6.6528e-02,  7.4477e-02],\n",
       "                        [ 1.4720e-02, -3.0189e-02, -6.9476e-02]],\n",
       "              \n",
       "                       [[ 2.4707e-02, -1.0053e-01,  2.7762e-02],\n",
       "                        [ 5.2119e-02, -9.2465e-02, -6.9009e-02],\n",
       "                        [-7.5781e-02,  8.8597e-02,  8.9611e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.5987e-03,  9.8959e-02, -3.5239e-02],\n",
       "                        [-1.0233e-01,  3.6819e-02,  3.7343e-02],\n",
       "                        [ 1.0334e-01, -3.0510e-05,  8.0785e-02]],\n",
       "              \n",
       "                       [[ 6.4612e-02,  7.6292e-02, -1.0460e-01],\n",
       "                        [ 8.6800e-02, -8.9856e-02,  9.4501e-02],\n",
       "                        [-4.3682e-03, -9.3415e-02,  2.9314e-02]],\n",
       "              \n",
       "                       [[-2.1456e-02, -9.4678e-02, -3.8215e-02],\n",
       "                        [ 1.0868e-02,  8.2098e-02, -3.2406e-02],\n",
       "                        [ 6.2610e-02,  1.3200e-02,  3.5531e-03]],\n",
       "              \n",
       "                       [[ 2.0170e-02, -6.9177e-02, -8.7616e-02],\n",
       "                        [-3.3121e-02, -9.8226e-02, -4.9158e-02],\n",
       "                        [ 4.8494e-03, -6.9424e-02, -4.3723e-02]],\n",
       "              \n",
       "                       [[-1.8941e-02, -1.2144e-02, -5.8187e-02],\n",
       "                        [ 5.0650e-03, -1.4795e-02,  3.0147e-02],\n",
       "                        [ 4.7611e-03, -5.2638e-02, -3.6291e-02]],\n",
       "              \n",
       "                       [[-1.2149e-03, -6.5774e-02,  8.2520e-03],\n",
       "                        [-7.4425e-03,  4.0897e-02,  2.4947e-02],\n",
       "                        [ 7.8887e-02, -3.4749e-03, -7.7887e-02]],\n",
       "              \n",
       "                       [[ 4.7119e-02, -7.1240e-02, -1.4489e-02],\n",
       "                        [-3.4132e-02, -3.9997e-02, -3.9000e-02],\n",
       "                        [ 9.6863e-02,  6.0342e-02,  2.9213e-02]],\n",
       "              \n",
       "                       [[ 9.8975e-02, -9.5524e-02,  1.7010e-02],\n",
       "                        [ 6.7481e-02,  7.0022e-02, -8.3890e-02],\n",
       "                        [ 3.7514e-02, -6.0050e-02, -4.1187e-03]],\n",
       "              \n",
       "                       [[-2.1996e-02, -8.8013e-02, -1.0055e-01],\n",
       "                        [-6.9349e-02,  4.7832e-02,  4.8218e-02],\n",
       "                        [-9.1681e-02, -3.9586e-02,  1.7218e-03]],\n",
       "              \n",
       "                       [[-9.1135e-02,  5.9393e-02,  9.5473e-02],\n",
       "                        [ 1.8643e-02, -7.8321e-02,  2.4580e-02],\n",
       "                        [ 3.8265e-02,  8.3468e-02, -5.6085e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-9.4437e-02,  4.6312e-02,  6.5624e-03],\n",
       "                        [-3.4345e-02, -4.4169e-02, -5.4351e-02],\n",
       "                        [ 8.5328e-02, -1.8187e-02,  7.6022e-02]],\n",
       "              \n",
       "                       [[ 9.4094e-02,  1.3353e-02,  2.2454e-02],\n",
       "                        [-7.1789e-03,  7.2397e-02, -9.4983e-02],\n",
       "                        [ 4.1919e-02, -1.7174e-02,  4.8132e-02]],\n",
       "              \n",
       "                       [[-4.6949e-04, -3.9029e-02, -1.1379e-02],\n",
       "                        [ 5.6920e-02, -7.3210e-02, -6.6629e-02],\n",
       "                        [-2.3611e-02, -3.8235e-02,  4.1409e-02]],\n",
       "              \n",
       "                       [[ 7.0937e-02, -1.1289e-02,  9.9672e-02],\n",
       "                        [-4.4042e-02, -5.9151e-02, -4.7191e-02],\n",
       "                        [-7.2624e-02, -7.3885e-02, -9.3921e-02]],\n",
       "              \n",
       "                       [[-9.3422e-02,  2.7512e-02,  6.4284e-02],\n",
       "                        [ 9.8963e-02,  8.9787e-02, -6.0709e-03],\n",
       "                        [ 2.0454e-02, -6.3068e-02,  4.0743e-02]],\n",
       "              \n",
       "                       [[-1.0107e-01,  4.9719e-02,  1.9334e-02],\n",
       "                        [ 3.2393e-02,  3.8595e-02, -4.8394e-02],\n",
       "                        [ 9.0452e-02,  5.0307e-02,  6.9243e-02]],\n",
       "              \n",
       "                       [[ 1.3922e-02,  6.6196e-02,  7.0941e-02],\n",
       "                        [ 4.7775e-02,  8.0297e-02, -1.9119e-02],\n",
       "                        [ 6.9310e-02,  2.4286e-02,  6.3424e-02]],\n",
       "              \n",
       "                       [[ 1.0267e-01,  2.3869e-02, -3.9124e-02],\n",
       "                        [-1.0488e-02,  2.9676e-02,  1.7773e-02],\n",
       "                        [-2.8795e-02,  8.2590e-02,  6.3331e-02]],\n",
       "              \n",
       "                       [[-6.5475e-02, -8.5889e-03, -1.0119e-02],\n",
       "                        [-6.6063e-02,  1.5374e-02, -3.2360e-02],\n",
       "                        [-5.4419e-02, -3.3894e-02, -3.7584e-02]],\n",
       "              \n",
       "                       [[ 1.0084e-01,  4.0432e-02,  1.0373e-01],\n",
       "                        [ 2.8903e-02,  2.3868e-02,  4.3333e-02],\n",
       "                        [ 1.8092e-02, -8.2722e-02, -6.2334e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-2.5538e-02,  1.5846e-03,  3.9709e-02],\n",
       "                        [ 4.0588e-02,  8.3623e-02,  2.1458e-02],\n",
       "                        [-3.5975e-02, -7.9271e-02, -7.7203e-02]],\n",
       "              \n",
       "                       [[-6.2965e-02,  3.1792e-02,  5.6950e-02],\n",
       "                        [ 9.2224e-02, -3.3342e-02, -8.3150e-03],\n",
       "                        [-3.1303e-02, -3.8517e-04,  3.3837e-02]],\n",
       "              \n",
       "                       [[-2.3160e-03,  4.8799e-03,  1.3354e-02],\n",
       "                        [ 3.9256e-02, -3.1981e-02, -6.2855e-02],\n",
       "                        [ 2.4869e-02, -1.2481e-02, -4.7753e-02]],\n",
       "              \n",
       "                       [[ 4.4268e-02,  9.5597e-04, -1.5333e-02],\n",
       "                        [-5.1027e-02, -1.3868e-02, -8.9632e-02],\n",
       "                        [ 2.3980e-02,  1.5818e-03,  6.3966e-02]],\n",
       "              \n",
       "                       [[ 6.8063e-03,  8.4277e-03,  2.8715e-02],\n",
       "                        [ 8.0210e-02, -4.9812e-02,  6.2930e-02],\n",
       "                        [ 2.5779e-02, -7.0320e-02,  3.6702e-02]],\n",
       "              \n",
       "                       [[-6.3217e-02, -3.3181e-02, -5.0245e-02],\n",
       "                        [-7.1711e-02,  8.3017e-02, -9.4217e-02],\n",
       "                        [ 5.2706e-02, -9.4870e-02, -1.2829e-02]],\n",
       "              \n",
       "                       [[ 6.2868e-03,  7.4937e-02, -3.8147e-02],\n",
       "                        [ 3.0340e-02,  1.6329e-02,  6.2021e-02],\n",
       "                        [ 6.2667e-03,  3.9470e-02, -6.3677e-02]],\n",
       "              \n",
       "                       [[-7.3250e-02,  9.3928e-02, -7.6808e-02],\n",
       "                        [-1.7945e-02, -1.2742e-02,  1.0308e-01],\n",
       "                        [-2.2780e-02, -8.0249e-02, -2.6721e-02]],\n",
       "              \n",
       "                       [[ 5.4372e-02,  4.1773e-02,  8.7204e-02],\n",
       "                        [-2.1579e-02,  4.9653e-02, -9.9194e-02],\n",
       "                        [ 4.0787e-02,  4.8432e-02,  6.7998e-02]],\n",
       "              \n",
       "                       [[-6.0446e-02, -2.8142e-02,  2.5502e-02],\n",
       "                        [-7.4905e-02, -8.3851e-02, -1.0141e-01],\n",
       "                        [ 5.8842e-03,  6.5458e-02,  2.7075e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 6.4263e-03,  3.6727e-02, -6.6240e-02],\n",
       "                        [ 1.1113e-02, -2.6186e-02, -5.2193e-02],\n",
       "                        [ 9.0902e-02, -8.1550e-02,  1.5448e-02]],\n",
       "              \n",
       "                       [[-9.2624e-02, -3.5762e-03, -4.6840e-02],\n",
       "                        [ 3.4695e-02, -5.9191e-02,  6.7466e-02],\n",
       "                        [-8.5536e-02,  6.3313e-02, -7.9181e-02]],\n",
       "              \n",
       "                       [[ 5.6456e-02, -4.4384e-02, -2.4556e-04],\n",
       "                        [-1.9238e-02,  6.8414e-02,  3.4546e-02],\n",
       "                        [-9.2887e-02,  9.6914e-03, -7.2718e-02]],\n",
       "              \n",
       "                       [[ 7.8800e-02,  1.7319e-02, -2.7109e-02],\n",
       "                        [-5.3777e-02,  3.6485e-02, -6.3129e-02],\n",
       "                        [ 4.9992e-02,  5.7519e-02,  6.4701e-02]],\n",
       "              \n",
       "                       [[ 2.7537e-02, -9.2272e-02,  7.5823e-02],\n",
       "                        [-3.2700e-02, -3.1163e-02, -1.1325e-02],\n",
       "                        [ 7.7068e-02,  8.1052e-02,  1.6276e-02]],\n",
       "              \n",
       "                       [[ 5.0296e-02, -9.8241e-02,  2.4900e-04],\n",
       "                        [-9.3254e-02,  3.5876e-02, -7.5099e-02],\n",
       "                        [-3.7568e-02,  7.3684e-02,  1.0074e-01]],\n",
       "              \n",
       "                       [[-6.3286e-02, -5.8503e-02,  1.3055e-02],\n",
       "                        [ 4.1437e-02, -1.7168e-02, -3.2918e-02],\n",
       "                        [-6.9237e-02,  4.4997e-02,  1.0328e-01]],\n",
       "              \n",
       "                       [[-5.1026e-02,  4.9718e-02,  5.1481e-02],\n",
       "                        [ 8.4728e-02, -1.2001e-02,  3.3202e-03],\n",
       "                        [ 7.7444e-02,  6.6631e-02,  1.0411e-01]],\n",
       "              \n",
       "                       [[-3.0207e-02,  4.1709e-02,  7.3605e-02],\n",
       "                        [-7.1553e-02,  2.0940e-02, -2.3586e-02],\n",
       "                        [ 6.7760e-02, -4.7342e-02,  7.3933e-03]],\n",
       "              \n",
       "                       [[ 6.3067e-02, -9.6567e-02, -8.9004e-02],\n",
       "                        [-5.3989e-02,  6.7611e-02,  7.0680e-02],\n",
       "                        [-7.1991e-02,  2.0100e-02, -5.5854e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-4.8926e-02,  9.0907e-02,  5.0914e-02],\n",
       "                        [-2.8828e-02,  1.5516e-02,  2.0424e-02],\n",
       "                        [ 2.4691e-02, -3.6079e-02, -6.2074e-02]],\n",
       "              \n",
       "                       [[ 6.9788e-02,  1.4164e-02,  4.4119e-02],\n",
       "                        [-3.9922e-02,  5.1057e-02,  7.6713e-02],\n",
       "                        [ 6.4107e-02,  2.8660e-02,  1.0371e-01]],\n",
       "              \n",
       "                       [[-2.3053e-04,  2.2441e-02,  1.0015e-01],\n",
       "                        [ 1.0245e-01, -4.4506e-02,  9.4953e-02],\n",
       "                        [ 3.8902e-02, -1.1799e-02,  9.2038e-02]],\n",
       "              \n",
       "                       [[-5.4605e-02,  6.8490e-02,  1.0445e-01],\n",
       "                        [-7.2701e-02, -6.2201e-02, -1.0445e-01],\n",
       "                        [-1.8970e-02, -9.5733e-02, -3.5304e-02]],\n",
       "              \n",
       "                       [[ 3.2002e-02,  7.4511e-02,  5.8717e-02],\n",
       "                        [ 5.8511e-02,  4.3730e-02, -6.5378e-02],\n",
       "                        [-8.3694e-02,  4.3696e-03,  1.0009e-01]],\n",
       "              \n",
       "                       [[ 5.9351e-03, -9.0662e-03, -7.1545e-02],\n",
       "                        [-5.2266e-02, -8.1256e-02,  8.4398e-02],\n",
       "                        [-1.7174e-02, -9.3119e-02,  1.1308e-02]],\n",
       "              \n",
       "                       [[ 7.6494e-03, -1.3023e-02,  3.7733e-02],\n",
       "                        [ 5.6687e-02, -9.9128e-02, -8.0753e-02],\n",
       "                        [-5.0639e-03, -9.7729e-02, -9.5750e-02]],\n",
       "              \n",
       "                       [[ 9.3067e-02, -8.0174e-03, -5.2113e-02],\n",
       "                        [-3.6157e-02, -8.2295e-02,  8.2258e-02],\n",
       "                        [-2.2857e-02, -5.9265e-02, -7.9944e-02]],\n",
       "              \n",
       "                       [[ 6.1611e-02, -1.4571e-02, -1.1074e-02],\n",
       "                        [-2.7473e-02, -5.0883e-02,  1.8751e-02],\n",
       "                        [ 8.1099e-02, -6.1093e-02,  5.0504e-03]],\n",
       "              \n",
       "                       [[-8.0165e-02, -4.9426e-02,  9.2525e-02],\n",
       "                        [ 1.1052e-03,  1.0154e-01, -1.8468e-02],\n",
       "                        [-5.7453e-02, -6.2981e-02,  9.3426e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.1058e-02,  5.5318e-02,  2.6203e-02],\n",
       "                        [ 3.1107e-02,  5.9476e-02, -2.7577e-02],\n",
       "                        [ 6.5223e-02, -8.3982e-02, -3.7087e-02]],\n",
       "              \n",
       "                       [[ 7.7164e-02,  3.1283e-02, -1.4038e-02],\n",
       "                        [-2.4616e-02, -6.4364e-02,  6.4098e-02],\n",
       "                        [-3.3520e-03, -3.5664e-03,  2.4929e-02]],\n",
       "              \n",
       "                       [[ 7.7787e-02, -5.3778e-02, -3.6303e-02],\n",
       "                        [ 7.1429e-02,  5.9532e-02, -5.1855e-02],\n",
       "                        [-1.0428e-01,  1.9555e-02,  5.5434e-02]],\n",
       "              \n",
       "                       [[ 2.5178e-02,  7.4768e-02, -8.3640e-02],\n",
       "                        [ 5.3156e-02, -6.5531e-02,  5.9325e-02],\n",
       "                        [ 7.8394e-02,  3.3385e-02,  8.5284e-02]],\n",
       "              \n",
       "                       [[-6.9481e-02, -9.4275e-02, -1.0135e-01],\n",
       "                        [ 6.6179e-02,  3.6926e-02, -7.7188e-02],\n",
       "                        [ 5.1048e-02,  9.6177e-02, -1.0394e-01]],\n",
       "              \n",
       "                       [[ 7.6466e-02,  1.6167e-02,  9.8053e-03],\n",
       "                        [ 9.4847e-02,  9.5458e-02,  4.4414e-02],\n",
       "                        [ 8.3288e-02,  4.3853e-02,  1.7176e-02]],\n",
       "              \n",
       "                       [[-9.2656e-02,  1.9689e-02, -7.4993e-02],\n",
       "                        [ 3.2452e-02,  1.8598e-02,  2.3681e-03],\n",
       "                        [-7.2071e-02, -6.3899e-02,  7.7912e-02]],\n",
       "              \n",
       "                       [[ 5.1336e-02,  5.5576e-02, -3.1410e-02],\n",
       "                        [-1.8151e-02, -2.7014e-02,  7.2489e-02],\n",
       "                        [-4.5504e-02,  6.6394e-02,  7.2679e-02]],\n",
       "              \n",
       "                       [[-9.6403e-02,  6.4369e-04, -2.0076e-02],\n",
       "                        [-5.8273e-02,  4.5507e-02, -1.2807e-02],\n",
       "                        [ 9.2287e-02, -6.5976e-02,  4.8976e-02]],\n",
       "              \n",
       "                       [[-8.9998e-02, -5.2833e-02,  7.1903e-03],\n",
       "                        [ 8.3283e-02,  5.5521e-02, -8.6550e-02],\n",
       "                        [ 1.1676e-02, -6.2138e-02,  4.5674e-03]]]], device='mps:0')),\n",
       "             ('conv_block2.0.bias',\n",
       "              tensor([-0.0878, -0.0309,  0.0723, -0.0967, -0.1005,  0.0192,  0.0144, -0.0193,\n",
       "                       0.0920, -0.0635], device='mps:0')),\n",
       "             ('conv_block2.2.weight',\n",
       "              tensor([[[[-6.3992e-02, -7.8791e-02, -1.9619e-02],\n",
       "                        [-2.6901e-02,  6.5222e-02, -5.9186e-03],\n",
       "                        [ 3.3663e-02, -4.3804e-02,  8.5507e-02]],\n",
       "              \n",
       "                       [[ 8.8862e-02, -9.4401e-02, -2.7090e-02],\n",
       "                        [-8.9439e-02,  4.4781e-02, -9.2094e-02],\n",
       "                        [-4.9839e-02,  1.0532e-01, -1.0066e-01]],\n",
       "              \n",
       "                       [[ 7.7771e-02,  8.9049e-03,  8.4289e-02],\n",
       "                        [-5.3494e-02,  6.9236e-02,  1.2718e-02],\n",
       "                        [ 8.1073e-03,  7.1945e-02, -1.0019e-01]],\n",
       "              \n",
       "                       [[-8.4902e-02,  1.0180e-01, -6.3298e-02],\n",
       "                        [-7.5980e-02, -5.1539e-03, -3.3742e-02],\n",
       "                        [-1.4421e-02, -7.0623e-02,  3.8034e-02]],\n",
       "              \n",
       "                       [[-9.0703e-02,  8.5374e-03,  6.1510e-02],\n",
       "                        [ 2.0253e-02,  1.4006e-02,  1.5418e-02],\n",
       "                        [-3.0880e-02, -2.0080e-02, -4.4450e-02]],\n",
       "              \n",
       "                       [[-7.1207e-02, -5.5810e-02,  1.0420e-01],\n",
       "                        [-1.7641e-02,  3.6924e-02,  7.2896e-02],\n",
       "                        [-8.2343e-03, -5.6707e-02, -7.1419e-02]],\n",
       "              \n",
       "                       [[-3.8833e-02,  3.7624e-02, -8.8771e-02],\n",
       "                        [-1.2870e-02,  4.0096e-02,  8.5999e-02],\n",
       "                        [ 3.1721e-02,  2.0846e-02,  7.2162e-02]],\n",
       "              \n",
       "                       [[ 4.8708e-02,  3.5661e-02, -3.2682e-02],\n",
       "                        [-8.4528e-02, -2.2769e-02, -1.9117e-02],\n",
       "                        [ 7.7410e-03, -1.1593e-02,  4.2616e-02]],\n",
       "              \n",
       "                       [[ 7.0050e-02, -4.2735e-02, -1.0002e-01],\n",
       "                        [-5.4081e-02, -5.0436e-02,  5.9750e-02],\n",
       "                        [-6.7994e-02, -9.9145e-03, -2.2340e-02]],\n",
       "              \n",
       "                       [[-6.3976e-02,  4.7780e-02, -4.3909e-02],\n",
       "                        [-5.4531e-03, -7.4112e-02, -1.0632e-02],\n",
       "                        [ 1.4977e-02, -4.2894e-03, -3.9386e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.1315e-02, -2.7311e-02, -5.8439e-02],\n",
       "                        [-7.7732e-02, -2.2329e-02, -9.9578e-02],\n",
       "                        [ 8.7492e-02, -5.0357e-02, -4.3684e-02]],\n",
       "              \n",
       "                       [[ 9.7439e-03,  2.7326e-02, -9.9393e-03],\n",
       "                        [ 7.2313e-02, -6.1448e-02,  3.7777e-02],\n",
       "                        [-2.3773e-04, -8.5747e-02, -4.0824e-02]],\n",
       "              \n",
       "                       [[ 2.6825e-02,  2.0138e-02,  7.6647e-02],\n",
       "                        [ 7.0518e-02, -5.7493e-02, -4.5013e-02],\n",
       "                        [-2.2351e-02, -7.5517e-02, -2.8459e-02]],\n",
       "              \n",
       "                       [[-8.6258e-02,  4.0092e-02,  7.4583e-02],\n",
       "                        [ 8.3459e-03, -7.5460e-02, -7.9827e-02],\n",
       "                        [-4.1036e-02,  3.0659e-02,  2.5711e-03]],\n",
       "              \n",
       "                       [[ 1.9166e-02,  9.9346e-02,  4.8956e-02],\n",
       "                        [ 2.2665e-02, -2.1327e-02,  4.9864e-02],\n",
       "                        [ 3.8563e-02, -9.4879e-02, -6.2266e-02]],\n",
       "              \n",
       "                       [[ 3.5381e-03,  3.9997e-02,  5.1282e-02],\n",
       "                        [-6.2748e-02, -1.0458e-01, -5.4909e-03],\n",
       "                        [-1.2050e-02,  3.0588e-02, -2.8988e-02]],\n",
       "              \n",
       "                       [[ 8.0588e-02,  7.0333e-03,  7.6975e-02],\n",
       "                        [-7.3398e-02,  4.2167e-02,  1.2560e-02],\n",
       "                        [-5.2720e-02,  5.2256e-02, -1.0372e-01]],\n",
       "              \n",
       "                       [[ 8.5220e-02,  8.4947e-03,  1.0178e-02],\n",
       "                        [ 4.8746e-02,  8.7503e-03,  4.5184e-02],\n",
       "                        [ 6.7063e-02, -8.2268e-02,  6.9735e-02]],\n",
       "              \n",
       "                       [[-1.5784e-02, -2.4513e-02,  2.1217e-02],\n",
       "                        [ 8.2446e-02, -5.7302e-02, -7.1039e-02],\n",
       "                        [ 6.5418e-02, -4.9507e-02,  3.3937e-02]],\n",
       "              \n",
       "                       [[-1.5530e-02,  2.9014e-02,  8.0439e-02],\n",
       "                        [-5.3421e-02, -5.1151e-02,  5.1716e-02],\n",
       "                        [ 5.7714e-03, -1.1601e-02, -9.2590e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.9309e-02, -3.9919e-03, -1.9415e-02],\n",
       "                        [-4.3269e-02, -2.0801e-02,  5.1233e-02],\n",
       "                        [-2.4227e-03,  9.0147e-02, -6.0858e-03]],\n",
       "              \n",
       "                       [[-1.5122e-02,  5.9498e-02, -2.7275e-03],\n",
       "                        [-2.1039e-02,  3.5231e-02,  8.3129e-02],\n",
       "                        [ 2.6305e-02,  7.3398e-02,  6.8309e-02]],\n",
       "              \n",
       "                       [[ 2.9810e-02,  3.6650e-02,  3.4014e-02],\n",
       "                        [ 1.0934e-02,  8.9675e-02,  9.7308e-02],\n",
       "                        [ 3.7524e-02, -5.2640e-03,  9.4509e-02]],\n",
       "              \n",
       "                       [[-8.2042e-02,  7.7453e-02,  5.5849e-02],\n",
       "                        [ 6.7687e-02, -8.0992e-03, -7.8646e-02],\n",
       "                        [ 7.5193e-02, -4.6091e-02,  2.7734e-02]],\n",
       "              \n",
       "                       [[ 5.9719e-02, -9.8508e-02,  6.9954e-03],\n",
       "                        [-3.7444e-02,  7.4815e-02, -6.7114e-02],\n",
       "                        [ 6.4001e-02,  6.5730e-02,  5.8156e-02]],\n",
       "              \n",
       "                       [[ 1.0119e-01,  1.5964e-02, -9.5541e-02],\n",
       "                        [ 7.5248e-02,  9.6499e-03,  2.0918e-03],\n",
       "                        [-1.0041e-01, -2.3691e-02, -5.1162e-02]],\n",
       "              \n",
       "                       [[ 1.0324e-01,  7.5054e-02,  7.8634e-02],\n",
       "                        [ 7.2188e-02, -6.5340e-02, -4.5270e-02],\n",
       "                        [-4.1252e-02, -4.2257e-02,  8.2054e-02]],\n",
       "              \n",
       "                       [[ 3.5815e-02,  8.4470e-02, -4.9309e-03],\n",
       "                        [-9.3965e-02, -3.0582e-02,  7.4081e-02],\n",
       "                        [ 6.4174e-02,  3.2632e-02, -3.0919e-02]],\n",
       "              \n",
       "                       [[-9.8386e-02, -5.6639e-02,  5.4958e-02],\n",
       "                        [-4.2518e-02,  5.0421e-02,  2.8781e-02],\n",
       "                        [-4.0486e-02,  6.4202e-02, -3.3871e-02]],\n",
       "              \n",
       "                       [[-3.5020e-03, -4.0152e-02, -9.9988e-02],\n",
       "                        [ 1.6996e-02,  3.0460e-02, -5.3072e-02],\n",
       "                        [ 6.4663e-02, -9.4558e-02, -1.0161e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-6.5106e-02, -3.6430e-02, -1.1707e-02],\n",
       "                        [-2.0370e-02,  4.8108e-02, -9.2510e-02],\n",
       "                        [ 1.5521e-02,  1.8254e-03,  2.7842e-02]],\n",
       "              \n",
       "                       [[ 1.0479e-01,  6.4874e-02, -5.8366e-02],\n",
       "                        [-8.6378e-02, -2.5520e-02, -5.2876e-02],\n",
       "                        [ 3.6820e-02,  9.6628e-04,  8.4783e-02]],\n",
       "              \n",
       "                       [[ 4.1405e-02, -1.9382e-02,  3.6229e-03],\n",
       "                        [ 2.5244e-02, -1.3080e-02,  8.5058e-02],\n",
       "                        [-8.2420e-02,  5.1377e-02, -6.7192e-02]],\n",
       "              \n",
       "                       [[-9.2347e-02, -2.1640e-02,  5.1366e-02],\n",
       "                        [ 7.4478e-02,  2.6452e-02, -9.1104e-03],\n",
       "                        [-5.9092e-03, -4.2731e-02, -9.4592e-03]],\n",
       "              \n",
       "                       [[-7.2831e-03,  8.9699e-02,  6.1690e-02],\n",
       "                        [-8.4351e-02,  4.3604e-04, -6.4834e-02],\n",
       "                        [-1.6733e-02, -8.3776e-02,  2.7402e-02]],\n",
       "              \n",
       "                       [[-7.6008e-02,  1.0406e-01,  7.9605e-02],\n",
       "                        [-7.2559e-02, -9.9239e-02,  4.1128e-03],\n",
       "                        [-2.9425e-02,  3.0945e-02, -7.1353e-02]],\n",
       "              \n",
       "                       [[ 4.3148e-02, -9.1047e-02, -5.5632e-02],\n",
       "                        [-5.5414e-02,  5.1007e-02, -2.7597e-03],\n",
       "                        [-1.0130e-01, -6.0201e-02, -4.8781e-02]],\n",
       "              \n",
       "                       [[-9.7802e-02,  1.3497e-02,  3.7561e-02],\n",
       "                        [-1.9340e-02, -4.1947e-02, -6.3926e-04],\n",
       "                        [-8.3725e-02, -6.4184e-02, -2.4040e-03]],\n",
       "              \n",
       "                       [[ 9.3643e-02, -3.2414e-02,  5.2247e-02],\n",
       "                        [-4.1484e-02, -2.8060e-02, -1.0034e-01],\n",
       "                        [ 8.7330e-02,  1.0264e-01, -2.2139e-03]],\n",
       "              \n",
       "                       [[ 6.6974e-02,  8.6219e-02,  5.2359e-02],\n",
       "                        [ 5.4288e-02, -1.0035e-01, -9.9050e-02],\n",
       "                        [-8.0906e-02,  3.2970e-02, -9.1177e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-8.0464e-02, -5.1092e-02, -9.7154e-02],\n",
       "                        [ 1.4203e-04,  1.5207e-02, -6.1686e-02],\n",
       "                        [ 6.9018e-02, -4.0018e-02, -2.9676e-02]],\n",
       "              \n",
       "                       [[ 8.0309e-02,  9.0499e-02, -1.2093e-02],\n",
       "                        [-7.5671e-02, -5.2881e-02,  1.3423e-02],\n",
       "                        [ 6.1790e-02,  5.2477e-02, -4.6547e-02]],\n",
       "              \n",
       "                       [[-9.9650e-02, -9.2249e-02, -3.3537e-02],\n",
       "                        [ 1.3223e-03, -4.7347e-02, -8.3348e-02],\n",
       "                        [ 1.1109e-02, -8.3668e-02, -8.0946e-02]],\n",
       "              \n",
       "                       [[-8.5692e-02, -2.8563e-02,  9.3104e-02],\n",
       "                        [ 4.1207e-02, -1.2498e-02,  2.1694e-02],\n",
       "                        [ 4.1975e-02,  6.1414e-04, -8.5020e-02]],\n",
       "              \n",
       "                       [[-6.4944e-02, -7.1610e-02, -2.6766e-03],\n",
       "                        [-9.6492e-02, -1.9166e-02, -3.8545e-02],\n",
       "                        [ 1.0345e-01,  8.5679e-02,  6.1227e-02]],\n",
       "              \n",
       "                       [[ 5.9116e-03, -3.4129e-02,  2.6887e-02],\n",
       "                        [-7.2830e-02, -4.4957e-02, -2.1175e-02],\n",
       "                        [-2.4766e-02, -9.9854e-02,  4.1903e-02]],\n",
       "              \n",
       "                       [[ 8.6803e-02, -5.8141e-02,  2.8415e-02],\n",
       "                        [-1.2225e-02, -3.8445e-03,  6.1443e-03],\n",
       "                        [ 9.1346e-02,  1.4124e-02, -6.6690e-02]],\n",
       "              \n",
       "                       [[-3.7917e-02,  5.1495e-02,  3.2893e-02],\n",
       "                        [ 2.0487e-03, -1.3912e-02, -4.1012e-02],\n",
       "                        [-3.7413e-02, -5.5602e-02,  1.7273e-02]],\n",
       "              \n",
       "                       [[ 2.9603e-02,  8.0717e-02, -2.3813e-02],\n",
       "                        [ 7.5461e-03,  6.8125e-02,  4.5852e-02],\n",
       "                        [ 1.3544e-02,  3.2390e-02,  5.4714e-03]],\n",
       "              \n",
       "                       [[-9.0419e-02,  4.0636e-03, -2.3040e-02],\n",
       "                        [ 9.5123e-02,  9.5145e-02,  2.0912e-02],\n",
       "                        [ 9.4215e-02, -5.4288e-02,  9.1619e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 9.0756e-02, -4.0288e-03, -8.4592e-02],\n",
       "                        [-3.4015e-02, -2.8189e-02,  1.7411e-03],\n",
       "                        [-9.5569e-02,  1.9535e-02, -4.3839e-02]],\n",
       "              \n",
       "                       [[-2.6989e-02, -5.4443e-02, -2.2255e-02],\n",
       "                        [-9.7896e-02, -5.5885e-02,  9.7108e-03],\n",
       "                        [ 6.9072e-02,  9.5790e-02, -7.9737e-02]],\n",
       "              \n",
       "                       [[ 4.4264e-02, -5.9419e-02, -8.1498e-02],\n",
       "                        [-4.6417e-03, -6.0468e-02, -9.0783e-02],\n",
       "                        [-9.8509e-02, -7.0556e-02,  8.6619e-02]],\n",
       "              \n",
       "                       [[ 5.8788e-02, -4.1726e-02, -7.0553e-02],\n",
       "                        [-8.1085e-02, -6.2246e-02, -4.3376e-02],\n",
       "                        [ 6.3308e-02,  3.4496e-02, -4.0622e-02]],\n",
       "              \n",
       "                       [[ 7.2567e-02, -6.5484e-02, -8.5876e-02],\n",
       "                        [ 2.3006e-02, -5.8123e-02,  2.9987e-02],\n",
       "                        [ 8.9306e-02, -4.9849e-02, -7.3556e-02]],\n",
       "              \n",
       "                       [[ 3.9676e-02, -9.5200e-02,  9.4044e-02],\n",
       "                        [-4.9780e-02,  5.0961e-02, -8.3818e-02],\n",
       "                        [-7.1348e-02,  1.1611e-02,  3.7463e-02]],\n",
       "              \n",
       "                       [[ 8.1734e-02,  8.8158e-02, -6.0623e-03],\n",
       "                        [-1.3552e-02,  1.7424e-02, -2.4486e-02],\n",
       "                        [ 3.5882e-03, -9.9828e-02, -8.6531e-02]],\n",
       "              \n",
       "                       [[ 7.2233e-02, -6.1597e-02,  8.3008e-02],\n",
       "                        [ 1.1568e-02,  2.5676e-02,  9.5804e-02],\n",
       "                        [-5.8628e-02, -1.6640e-02,  1.8675e-02]],\n",
       "              \n",
       "                       [[ 3.6012e-02, -1.0259e-01,  3.7464e-02],\n",
       "                        [-6.2163e-02,  1.3846e-02,  7.1315e-02],\n",
       "                        [-1.0500e-02, -3.3346e-03, -7.8757e-03]],\n",
       "              \n",
       "                       [[ 8.7962e-02,  5.9907e-02,  1.7727e-02],\n",
       "                        [-6.3437e-02, -5.7241e-02,  8.3964e-02],\n",
       "                        [ 7.5834e-02,  6.1033e-02, -8.2189e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 8.2092e-02, -1.0076e-02,  7.7661e-02],\n",
       "                        [ 9.1553e-02,  1.1554e-02, -4.3863e-02],\n",
       "                        [ 9.9153e-02, -5.4931e-02,  6.8876e-02]],\n",
       "              \n",
       "                       [[-1.0108e-01, -3.3153e-02, -9.1902e-02],\n",
       "                        [-4.7284e-02,  4.4759e-02, -7.5529e-02],\n",
       "                        [-9.1158e-02,  7.5371e-02,  5.6270e-02]],\n",
       "              \n",
       "                       [[-1.1527e-03, -7.4309e-02, -2.7927e-02],\n",
       "                        [-3.4129e-02,  6.5100e-02, -3.4478e-02],\n",
       "                        [-3.0360e-02, -7.4720e-02, -4.9646e-02]],\n",
       "              \n",
       "                       [[ 5.7074e-02,  6.7914e-02,  1.5315e-02],\n",
       "                        [-3.9549e-02,  1.0124e-01,  2.0806e-02],\n",
       "                        [-4.0688e-02, -3.6535e-02, -1.4752e-02]],\n",
       "              \n",
       "                       [[ 4.9974e-02,  3.8555e-02,  7.6418e-02],\n",
       "                        [-4.7494e-03,  8.7183e-02, -4.2816e-02],\n",
       "                        [-4.8547e-02, -3.8927e-02, -9.8896e-02]],\n",
       "              \n",
       "                       [[-6.9195e-02, -9.5382e-02, -6.2294e-03],\n",
       "                        [ 9.9374e-04, -2.7358e-02, -7.2035e-02],\n",
       "                        [ 9.5637e-02, -3.4926e-02,  5.0233e-02]],\n",
       "              \n",
       "                       [[ 7.3408e-02, -6.9291e-02, -1.3179e-02],\n",
       "                        [ 6.0923e-02,  1.0218e-01, -1.3299e-02],\n",
       "                        [ 7.6382e-02, -8.2732e-02, -6.8489e-02]],\n",
       "              \n",
       "                       [[ 8.6682e-02, -9.9801e-03,  1.0414e-01],\n",
       "                        [ 7.6651e-03, -4.3714e-02,  1.0011e-01],\n",
       "                        [ 9.2179e-02,  9.7826e-03, -6.3900e-02]],\n",
       "              \n",
       "                       [[-4.5639e-03, -5.0693e-02,  7.6810e-02],\n",
       "                        [ 4.8829e-03,  2.2191e-02,  6.3927e-02],\n",
       "                        [ 3.4916e-02, -6.5803e-02,  8.7566e-02]],\n",
       "              \n",
       "                       [[ 6.4758e-02, -6.5073e-02,  7.9700e-02],\n",
       "                        [ 2.9905e-02, -2.0750e-02, -7.5385e-02],\n",
       "                        [-1.7490e-02, -1.0335e-01,  6.0163e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 7.6343e-02, -3.0347e-02,  9.7720e-02],\n",
       "                        [-3.9032e-02,  1.8051e-02, -7.3459e-02],\n",
       "                        [-4.4565e-03,  4.2610e-02,  4.5403e-02]],\n",
       "              \n",
       "                       [[-3.5346e-03, -5.3154e-02,  7.3680e-02],\n",
       "                        [ 6.9788e-02,  1.6916e-02, -4.8475e-02],\n",
       "                        [ 2.2349e-02,  2.8186e-04,  9.6302e-02]],\n",
       "              \n",
       "                       [[ 1.5621e-02,  8.1301e-03,  7.2057e-03],\n",
       "                        [ 5.6079e-02, -1.3024e-03,  9.0351e-02],\n",
       "                        [ 5.4917e-02, -7.9650e-02, -1.2063e-06]],\n",
       "              \n",
       "                       [[-8.9472e-02, -8.0934e-02,  2.0480e-02],\n",
       "                        [ 2.3687e-02, -9.2246e-03,  1.0019e-01],\n",
       "                        [-5.6627e-02, -4.4176e-02, -1.6881e-02]],\n",
       "              \n",
       "                       [[ 6.3911e-04, -8.9284e-03,  9.4909e-02],\n",
       "                        [-4.4519e-02, -5.5137e-02,  9.0599e-03],\n",
       "                        [ 7.9171e-02,  2.5019e-02,  5.6787e-02]],\n",
       "              \n",
       "                       [[ 2.0406e-02,  8.9839e-02,  6.3311e-02],\n",
       "                        [ 7.5428e-02, -1.4198e-02, -8.7268e-02],\n",
       "                        [-5.0002e-02,  3.5910e-02,  7.3950e-02]],\n",
       "              \n",
       "                       [[-4.1184e-02,  8.7218e-02,  1.5150e-02],\n",
       "                        [ 4.1869e-04,  4.1093e-03, -1.8623e-02],\n",
       "                        [ 9.8683e-02,  4.5784e-03,  6.4564e-02]],\n",
       "              \n",
       "                       [[-8.8967e-02, -5.4309e-02,  1.1852e-02],\n",
       "                        [ 8.4169e-02,  5.0184e-02,  2.0076e-02],\n",
       "                        [-1.0414e-01,  1.9816e-03, -6.9581e-02]],\n",
       "              \n",
       "                       [[-9.0006e-02,  1.4414e-02, -6.6693e-02],\n",
       "                        [ 9.5674e-02, -5.7294e-02,  3.3970e-02],\n",
       "                        [ 6.1871e-02, -8.1928e-02,  5.3946e-02]],\n",
       "              \n",
       "                       [[-1.4114e-02,  5.4619e-02,  1.0201e-01],\n",
       "                        [-4.4922e-02, -4.5653e-02,  8.3753e-02],\n",
       "                        [ 1.1722e-02, -1.0513e-02,  7.9971e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-5.0928e-02, -5.2047e-03,  7.2403e-02],\n",
       "                        [ 4.1195e-02, -6.8180e-02,  2.7398e-02],\n",
       "                        [-8.0368e-02, -5.7245e-02,  6.7779e-02]],\n",
       "              \n",
       "                       [[-2.8093e-02, -5.3691e-02,  7.4717e-03],\n",
       "                        [ 2.5759e-02, -6.5524e-02, -7.1084e-02],\n",
       "                        [-1.0209e-01,  2.7236e-02, -6.8013e-02]],\n",
       "              \n",
       "                       [[ 8.0331e-03, -2.3576e-02, -6.8923e-02],\n",
       "                        [-3.3636e-02, -8.1027e-02, -5.5797e-02],\n",
       "                        [-3.2857e-03, -9.0116e-02, -9.2447e-02]],\n",
       "              \n",
       "                       [[ 7.8958e-02,  9.9188e-03, -4.6618e-02],\n",
       "                        [-3.5047e-03,  7.8168e-02, -8.7939e-02],\n",
       "                        [-5.5886e-02, -7.6226e-02, -7.6634e-03]],\n",
       "              \n",
       "                       [[-3.6274e-03, -8.2146e-02,  7.3163e-02],\n",
       "                        [-8.0946e-02,  9.8414e-02, -7.2560e-02],\n",
       "                        [-1.4446e-02,  1.9710e-02, -4.6852e-02]],\n",
       "              \n",
       "                       [[ 9.6939e-02, -7.2673e-02, -5.8427e-03],\n",
       "                        [-7.7398e-02,  2.9261e-02,  8.9871e-02],\n",
       "                        [ 9.7776e-02,  1.2514e-02, -5.2773e-02]],\n",
       "              \n",
       "                       [[ 1.0244e-01,  7.8667e-03,  7.1317e-02],\n",
       "                        [-5.4751e-02, -4.8920e-02, -8.7504e-02],\n",
       "                        [ 9.6990e-02,  1.7486e-02, -7.5704e-02]],\n",
       "              \n",
       "                       [[ 9.0535e-03, -4.5211e-02,  5.2659e-03],\n",
       "                        [ 3.4988e-02, -5.2308e-02,  1.8394e-02],\n",
       "                        [-6.6553e-02,  2.0312e-02, -1.0178e-01]],\n",
       "              \n",
       "                       [[ 1.6797e-02,  1.0473e-01,  9.7094e-02],\n",
       "                        [ 3.8451e-02,  7.7563e-02,  1.0248e-01],\n",
       "                        [ 2.9870e-02,  3.5156e-02,  1.3707e-02]],\n",
       "              \n",
       "                       [[ 9.3322e-02,  9.0551e-02, -4.9570e-02],\n",
       "                        [-4.3333e-03, -5.3110e-02,  3.7824e-02],\n",
       "                        [-1.0214e-01,  3.7301e-02, -2.8929e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 3.8227e-02,  3.2899e-02, -5.2454e-02],\n",
       "                        [ 5.4687e-02,  4.4762e-02, -8.9602e-02],\n",
       "                        [ 1.0517e-01,  9.0731e-02,  6.5584e-02]],\n",
       "              \n",
       "                       [[-1.0699e-02,  3.7345e-02, -5.7028e-02],\n",
       "                        [-3.5818e-02,  4.9749e-02,  4.6925e-02],\n",
       "                        [ 4.1741e-02, -1.0053e-01,  8.7350e-02]],\n",
       "              \n",
       "                       [[-4.4028e-02,  9.1223e-02,  8.6852e-02],\n",
       "                        [ 3.9070e-02,  1.0502e-01,  6.0528e-02],\n",
       "                        [ 6.1821e-02, -3.5794e-02,  9.7766e-02]],\n",
       "              \n",
       "                       [[ 2.7627e-02,  6.2280e-02, -2.3834e-02],\n",
       "                        [ 7.6340e-02,  9.3509e-02, -8.0770e-02],\n",
       "                        [ 8.6415e-02, -6.9664e-02, -7.2571e-02]],\n",
       "              \n",
       "                       [[-8.8089e-02,  3.0459e-02, -7.9144e-02],\n",
       "                        [-3.9680e-02, -5.2988e-02,  2.8172e-02],\n",
       "                        [-1.0349e-01, -4.8324e-02,  7.7112e-04]],\n",
       "              \n",
       "                       [[ 9.4660e-03, -4.7605e-02,  3.7764e-02],\n",
       "                        [-6.9544e-02, -8.9270e-02, -1.4986e-02],\n",
       "                        [-5.6989e-02,  6.6443e-02, -7.2049e-02]],\n",
       "              \n",
       "                       [[-8.8494e-03,  4.3782e-02, -9.2311e-02],\n",
       "                        [ 8.1599e-02, -4.7895e-02, -2.8684e-02],\n",
       "                        [-6.4480e-02, -3.9279e-02, -4.0645e-02]],\n",
       "              \n",
       "                       [[-9.3801e-02,  3.6019e-02, -3.3768e-04],\n",
       "                        [ 1.0311e-01,  7.1117e-02,  9.1699e-02],\n",
       "                        [ 3.1014e-02,  5.5388e-02,  9.8704e-02]],\n",
       "              \n",
       "                       [[ 8.6545e-02, -8.0996e-02, -2.3636e-02],\n",
       "                        [-1.0166e-01,  3.9877e-03, -3.7229e-02],\n",
       "                        [ 9.1486e-02,  1.6666e-02,  1.1601e-03]],\n",
       "              \n",
       "                       [[-7.6248e-02, -8.2718e-02,  1.6594e-02],\n",
       "                        [-5.2376e-02, -4.8409e-02,  7.3938e-02],\n",
       "                        [-5.4952e-02, -4.6918e-02,  8.0934e-02]]]], device='mps:0')),\n",
       "             ('conv_block2.2.bias',\n",
       "              tensor([ 0.0412, -0.0599,  0.0319,  0.0531, -0.0936,  0.0197,  0.0241, -0.0041,\n",
       "                       0.1011, -0.0697], device='mps:0')),\n",
       "             ('classifier.1.weight',\n",
       "              tensor([[ 0.0245, -0.0240, -0.0387,  ...,  0.0094, -0.0015, -0.0225],\n",
       "                      [ 0.0228,  0.0067, -0.0439,  ..., -0.0302,  0.0368,  0.0293],\n",
       "                      [ 0.0303,  0.0347, -0.0211,  ...,  0.0207, -0.0423, -0.0240],\n",
       "                      ...,\n",
       "                      [-0.0359, -0.0343,  0.0166,  ...,  0.0324,  0.0113, -0.0143],\n",
       "                      [-0.0294, -0.0316,  0.0251,  ..., -0.0056,  0.0300, -0.0396],\n",
       "                      [-0.0246, -0.0035, -0.0046,  ..., -0.0146, -0.0358,  0.0175]],\n",
       "                     device='mps:0')),\n",
       "             ('classifier.1.bias',\n",
       "              tensor([ 0.0320, -0.0445,  0.0246, -0.0357, -0.0442,  0.0156, -0.0010, -0.0277,\n",
       "                       0.0404,  0.0037], device='mps:0'))])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_02.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "81a00ba5-d133-4782-bb9e-735eff1d7ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single conv2d Layer\n",
    "\n",
    "conv_layer = nn.Conv2d(in_channels = 3,\n",
    "                       out_channels = 64,\n",
    "                       kernel_size=5,\n",
    "                       stride =2,\n",
    "                       padding =0)\n",
    "\n",
    "# Pass the test image through the convolutional layer\n",
    "output_image = conv_layer(test_image)\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4319e7c6-c8ca-478d-bb9a-f6fefc238827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image shape: torch.Size([3, 64, 64])\n",
      "Output image shape: torch.Size([64, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test image shape: {test_image.shape}\")\n",
    "print(f\"Output image shape: {output_image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c6c22-7e00-44c5-9f25-547e3617b232",
   "metadata": {},
   "source": [
    "## Manual Shape Calculation for Gray Scale Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "867fc89b-3509-4195-8e07-7e720d347073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_calculation(input_image: int, \n",
    "                     padding: int,\n",
    "                     stride: int,\n",
    "                     kernel_size: int,\n",
    "                     dilation: int,\n",
    "                     ):\n",
    "    _,H,W = input_image.shape\n",
    "    H_out = ((H+(2*padding[0])-dilation[0]*(kernel_size[0]-1)-1)/stride[0])+1\n",
    "    W_out = ((W+(2*padding[1])-dilation[1]*(kernel_size[1]-1)-1)/stride[1])+1\n",
    "\n",
    "\n",
    "    return H_out,W_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e1ec0edd-af9c-49b0-b5ca-00e4901db4ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 14])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_for_shape = torch.randn(size=(1,14,14))\n",
    "test_image_for_shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dec50985-22f7-4c78-b29f-f12496bdf3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_shape = shape_calculation(test_image_for_shape,\n",
    "                             padding=(1,1),\n",
    "                             stride =(1,1),\n",
    "                             kernel_size=(3,3),\n",
    "                             dilation=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "74ad17ad-e765-4e03-ac2d-8f88fbdea27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.0, 14.0)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19819c7c-ea15-463d-8fcf-213072ad124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup Loss function/eval metrics/optimizer\n",
    "from helper_functions import accuracy_fn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params = model_02.parameters(),\n",
    "                           lr = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dfe3aa-3f44-456f-9e94-bbcb573a3386",
   "metadata": {},
   "source": [
    "# Training and Testing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ffa1b1cf-ea94-43d3-9f40-77a90ad5571d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151706c56cef4b2f80e16efe66289cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0....\n",
      "Train loss: 0.59367 | Train accuracy 78.50333\n",
      "Avg test Loss: 0.3914 | Avg accuracy: 86.0124\n",
      "Epoch: 1....\n",
      "Train loss: 0.36027 | Train accuracy 86.85167\n",
      "Avg test Loss: 0.3472 | Avg accuracy: 87.4601\n",
      "Epoch: 2....\n",
      "Train loss: 0.32369 | Train accuracy 88.32167\n",
      "Avg test Loss: 0.3241 | Avg accuracy: 88.3886\n",
      "Train time on mps: 60.35410395899089 seconds\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "torch.manual_seed(42)\n",
    "torch.mps.manual_seed(42)\n",
    "\n",
    "# Measure Time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_model_2 = timer()\n",
    "\n",
    "# Train and test model\n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}....\")\n",
    "    train = training_loop(model = model_02,\n",
    "                         train_data = train_dataloader,\n",
    "                         Loss = loss_fn,\n",
    "                         optimizer = optimizer,\n",
    "                         accuracy_fn=accuracy_fn)\n",
    "    test = testing_loop(model = model_02,\n",
    "                       test_data=test_dataloader,\n",
    "                       Loss = loss_fn,\n",
    "                       accuracy_fn = accuracy_fn)\n",
    "train_time_end_model_02 = timer()\n",
    "total_train_time_model_02 = print_train_time(start = train_time_start_model_2,\n",
    "                                            end = train_time_end_model_02,\n",
    "                                            device = device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb3b4e2-75bc-4bea-9f77-365e175ec6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af28eb25-bc4a-47d4-91a9-2c88f1bee4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d4dd3-bfb7-447c-a77e-22553d64b631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0d83a-e132-4d37-bd5d-03805df368a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692cf90f-faf8-49ab-b5f4-3b945e4d3028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12cb96-2a8c-42ba-a202-4cd3bc8a6ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
